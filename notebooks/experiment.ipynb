{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "torch.cuda.empty_cache()\n",
    "import sys\n",
    "sys.path.append('./../src')\n",
    "import globals\n",
    "from model import MnistCNN, TinyImageNetCNN, Cifar10CNN\n",
    "from training import train_model, train_model_CL\n",
    "from visualizations import plot_embeddings, plot_confusion_matrix\n",
    "from feature_attribution import Feature_Importance_Evaluations\n",
    "from pytorch_utils import get_features, get_labels\n",
    "from data_utils import initialize_data\n",
    "from embedding_measurements import measure_embedding_confusion_knn, measure_embedding_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "import os\n",
    "\n",
    "RUN_LOCALLY = True  # With False it runs on the Slurm Cluster \n",
    "\n",
    "partition = ''\n",
    "\n",
    "timelimit_hours = 8\n",
    "num_gpus_per_node = 1\n",
    "num_jobs = 1\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "log_path = os.path.join(parent_dir, 'submitit_logs')\n",
    "run_path = os.path.join(parent_dir, 'src')\n",
    "\n",
    "\n",
    "ex_parallel = submitit.AutoExecutor(folder=log_path)\n",
    "ex_parallel.update_parameters(\n",
    "        slurm_signal_delay_s=180,\n",
    "        tasks_per_node=num_gpus_per_node,\n",
    "        nodes=1,\n",
    "        slurm_partition=partition,\n",
    "        timeout_min=int(timelimit_hours*60),\n",
    "        cpus_per_task=8,\n",
    "        slurm_gres=f'gpu:{num_gpus_per_node}',\n",
    "        slurm_setup = [f'export PYTHONPATH=\"${{PYTHONPATH}}:{run_path}\"'],\n",
    "    )\n",
    "SEED = globals.SEED\n",
    "DEVICE = globals.DEVICE if RUN_LOCALLY else torch.device(\"cuda:0\")\n",
    "full_trainset = globals.full_trainset\n",
    "trainset = globals.trainset\n",
    "testset = globals.testset\n",
    "trainloaders = globals.trainloaders\n",
    "valloaders = globals.valloaders\n",
    "testloaders = globals.testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(model, attr_device, i, only_pred = False):\n",
    "    accumPred = []\n",
    "    all_labels = []\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for j in range(i+1):\n",
    "            val_loader = globals.testloaders[j]\n",
    "            val_labels = get_labels(val_loader).to(attr_device)\n",
    "            model.eval()\n",
    "            pred, embeddings = model.get_pred_and_embeddings((get_features(val_loader).to(attr_device)))\n",
    "            model.train()\n",
    "            accumPred.append(pred)\n",
    "            if not only_pred:\n",
    "                all_embeddings.append(embeddings)\n",
    "                all_labels.append(val_labels)\n",
    "    accumPred = torch.cat(accumPred)\n",
    "    if not only_pred:\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_embeddings = torch.cat(all_embeddings)\n",
    "    if globals.OOD_CLASS == 1:\n",
    "        accumPred = accumPred[:,[i for i in range(accumPred.size(1)) if (i + 1) % (globals.CLASSES_PER_ITER+1) != 0]]\n",
    "    predicted = torch.argmax(accumPred, dim=1)\n",
    "    return predicted, all_labels, all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "        verbose = False,\n",
    "        full_CE = True,\n",
    "        with_OOD = False,\n",
    "        kd_loss = 0,\n",
    "        stopOnValAcc = None,\n",
    "        epochs = 1000000,\n",
    "        with_dropout = False,\n",
    "        optimiser_type = 'sgd',\n",
    "        dataset = 'mnist',\n",
    "        joint_training = False,\n",
    "        save_saliency=False,\n",
    "        plotting=False,\n",
    "        lr=0.003\n",
    "        ):\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    if dataset == 'tiny_imagenet':\n",
    "        ogd_basis_size=None\n",
    "        patience = 6\n",
    "        ood_method = 'jigsaw'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 200\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 40\n",
    "            globals.ITERATIONS = 5\n",
    "    elif dataset == 'mnist':\n",
    "        ogd_basis_size=200\n",
    "        patience = 2\n",
    "        ood_method = 'jigsaw'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 2\n",
    "            globals.ITERATIONS = 5\n",
    "    elif dataset == 'cifar10':\n",
    "        ogd_basis_size=50\n",
    "        patience = 4\n",
    "        ood_method = 'jigsaw'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 2\n",
    "            globals.ITERATIONS = 5\n",
    "    if with_OOD:\n",
    "        globals.toggle_OOD(ood_method)\n",
    "    else:\n",
    "        globals.disable_OOD()\n",
    "    initialize_data(dataset)\n",
    "    prevModel = None\n",
    "    \n",
    "    globals.WITH_DROPOUT = with_dropout\n",
    "\n",
    "    #[Denis] added code:\n",
    "    if dataset == 'tiny_imagenet' or dataset == 'cifar10':\n",
    "        attr_device = 'cpu' # CPU has high memory in the cluster\n",
    "    else:\n",
    "        attr_device = globals.DEVICE\n",
    "    Feature_Importance_Eval=Feature_Importance_Evaluations(globals.testloaders, attr_device)\n",
    "\n",
    "    for i in tqdm(range(globals.ITERATIONS), desc=\"Experiment Progress\"):\n",
    "        if dataset == 'mnist':\n",
    "            model = MnistCNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        elif dataset == 'tiny_imagenet':\n",
    "            model = TinyImageNetCNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        elif dataset == 'cifar10':\n",
    "            model = Cifar10CNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        if prevModel is not None:\n",
    "            with torch.no_grad():\n",
    "                model.copyPrev(prevModel)\n",
    "        train_loader = globals.trainloaders[i]\n",
    "        val_loader = globals.valloaders[i]\n",
    "        if prevModel:\n",
    "            _print(\"CL TRAIN!!\")\n",
    "            model = train_model_CL(\n",
    "                model,\n",
    "                prevModel,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                i,\n",
    "                verbose,\n",
    "                epochs,\n",
    "                True,\n",
    "                kd_loss=kd_loss,\n",
    "                stopOnLoss=None,\n",
    "                stopOnValAcc = stopOnValAcc,\n",
    "                full_CE=full_CE,\n",
    "                optimiser_type=optimiser_type,\n",
    "                plotting=plotting,\n",
    "                patience=patience,\n",
    "                ogd_basis_size=ogd_basis_size,\n",
    "                lr=lr\n",
    "                )\n",
    "        else:\n",
    "            _print(\"TRAINING!\")\n",
    "            model = train_model(\n",
    "                model, \n",
    "                train_loader,\n",
    "                val_loader, \n",
    "                verbose, \n",
    "                epochs=epochs, \n",
    "                stopOnLoss=None,\n",
    "                optimiser_type=optimiser_type,\n",
    "                plotting=plotting,\n",
    "                patience=patience,\n",
    "                ogd_basis_size=ogd_basis_size,\n",
    "                lr=lr\n",
    "                )\n",
    "\n",
    "        #[Denis] added code:\n",
    "        Feature_Importance_Eval.Task_Feature_Attribution(model, i)\n",
    "        \n",
    "        if verbose or i == globals.ITERATIONS-1:\n",
    "            if dataset == 'tiny_imagenet' or dataset == 'cifar10':\n",
    "                model.to(attr_device)\n",
    "            _print(\"Starting evaluation\")\n",
    "            _print(\"ITERATION\", i+1)\n",
    "            \n",
    "            predicted, all_labels, all_embeddings = evalModel(model, attr_device, i)\n",
    "            if dataset == 'tiny_imagenet' or dataset == 'cifar10':\n",
    "                model.to(DEVICE)\n",
    "            predicted = predicted.to(attr_device)\n",
    "            correct = (predicted == all_labels).sum().item()  # Count how many were correct\n",
    "            accuracy = correct / all_labels.size(0)  # Accuracy as a percentage\n",
    "            _print(\"Accuracy on tasks so far:\", accuracy)\n",
    "            embedding_drift = measure_embedding_drift(all_embeddings, all_labels, model.prev_test_embedding_centers)\n",
    "            _print(\"Average embedding drift based on centroids:\", embedding_drift)\n",
    "            total_confusion, intra_phase_confusion, per_task_confusion = measure_embedding_confusion_knn(all_embeddings, all_labels, k = 300, task=i+1)\n",
    "            _print(\"Total confusion\", total_confusion)\n",
    "            _print(\"Intra-phase confusion\", intra_phase_confusion)\n",
    "            _print(\"Per task confusions\", per_task_confusion)\n",
    "            if verbose and dataset == 'mnist':\n",
    "                plot_confusion_matrix(predicted.cpu(), all_labels.cpu(), list(range(globals.CLASSES_PER_ITER*(i+1))))\n",
    "        prevModel = model\n",
    "        \n",
    "    #[Denis] added code:\n",
    "    [avg_att_diff,att_diffs,_,_,avg_att_spread,att_spreads]=Feature_Importance_Eval.Get_Feature_Change_Score(prevModel)\n",
    "    _print(\"Average SHAPC values (ordered as tasks):\", att_diffs)\n",
    "    _print(\"Averaged SHAPC value (the smaller the better):\", avg_att_diff)\n",
    "    _print(\"Average attention spread values (ordered as tasks):\", att_spreads)\n",
    "    _print(\"Averaged attention spread value (the bigger the better):\", avg_att_spread)\n",
    "    if save_saliency:\n",
    "        Feature_Importance_Eval.Save_Random_Picture_Salency() #prints the salcency maps for 1 example by class (first row: image, second row: salency map after training, third row: salency map after training task where class is included)\n",
    "    if not joint_training:\n",
    "        _print(\"Training output layer to check for bias...\")\n",
    "        model.output_layer.reset_parameters()\n",
    "        globals.ITERATIONS = 1\n",
    "        if dataset == 'mnist' or dataset == 'cifar10':\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 200\n",
    "        model = train_model(\n",
    "                    model, \n",
    "                    DataLoader(globals.trainset, batch_size=globals.BATCH_SIZE, shuffle=True, pin_memory=True, num_workers = 0), \n",
    "                    DataLoader(globals.valset, batch_size=100, shuffle=False), \n",
    "                    verbose, \n",
    "                    epochs=epochs, \n",
    "                    stopOnLoss=None,\n",
    "                    optimiser_type='sgd',\n",
    "                    plotting=plotting,\n",
    "                    patience=patience,\n",
    "                    ogd_basis_size=ogd_basis_size,\n",
    "                    only_output_layer=True\n",
    "                    )\n",
    "        model.to(attr_device)\n",
    "        predicted, _, _ = evalModel(model, attr_device, i, True)\n",
    "        predicted = predicted.to(attr_device)\n",
    "        correct = (predicted == all_labels).sum().item()  # Count how many were correct\n",
    "        unbiased_output_accuracy = correct / all_labels.size(0)  # Accuracy as a percentage\n",
    "        output_bias = unbiased_output_accuracy-accuracy\n",
    "    else:\n",
    "        output_bias = 0\n",
    "    return accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread, output_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(n_runs=globals.EXPERIMENT_N_RUNS, *args, **kwargs):\n",
    "    \n",
    "    verbose = kwargs.get('verbose', None)\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    jobs = []\n",
    "    for r in range(n_runs):\n",
    "        print(f\"Starting run {r+1}.\")\n",
    "        if RUN_LOCALLY:\n",
    "            jobs.append(run_experiment(*args, **kwargs))\n",
    "        else:  # Run on Cluster\n",
    "            jobs.append(ex_parallel.submit(run_experiment,*args, **kwargs))\n",
    "    return jobs\n",
    "\n",
    "def report_performance(jobs):\n",
    "    def report_stats(data, name):\n",
    "        #print(name, data)\n",
    "        mean = statistics.mean(data)\n",
    "        std = statistics.stdev(data)\n",
    "        print(f\"Mean \" + name + f\" across {len(jobs)} runs: {mean}\")\n",
    "        print(f\"Standard deviation of \" + name + f\" across {len(jobs)} runs: {std}\\n\")\n",
    "    accuracies = []\n",
    "    total_confusions = []\n",
    "    intra_phase_confusions = []\n",
    "    per_task_confusions = []\n",
    "    att_diffs = []\n",
    "    embedding_drifts = []\n",
    "    att_spreads = []\n",
    "    output_biases = []\n",
    "    for i, job in enumerate(jobs):\n",
    "        print(f\"Finished run {i+1}.\")\n",
    "        if type(job) == submitit.slurm.slurm.SlurmJob:\n",
    "            accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread, output_bias = job.result()\n",
    "        else:\n",
    "            accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread, output_bias = job\n",
    "        accuracies.append(accuracy)\n",
    "        total_confusions.append(total_confusion)\n",
    "        intra_phase_confusions.append(intra_phase_confusion)\n",
    "        per_task_confusions.append(per_task_confusion)\n",
    "        att_diffs.append(avg_att_diff)\n",
    "        embedding_drifts.append(embedding_drift)\n",
    "        att_spreads.append(avg_att_spread)\n",
    "        output_biases.append(output_bias)\n",
    "        print(f\"Run {i} finished with accuracy {accuracy}\")\n",
    "\n",
    "    report_stats(accuracies, \"accuracy\")\n",
    "    report_stats(total_confusions, \"total confusion\")\n",
    "    report_stats(intra_phase_confusions, \"intra-phase confusion\")\n",
    "    report_stats(per_task_confusions, \"per-task confusion\")\n",
    "    report_stats(output_biases, \"output bias\")\n",
    "    report_stats(embedding_drifts, \"embedding drift\")\n",
    "    report_stats(att_diffs, \"attention drift\")\n",
    "    report_stats(att_spreads, \"attention spread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "ex1 = run_experiments(dataset='mnist', n_runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1965\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1975\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1974\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.1966\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1971\n",
      "Mean accuracy across 5 runs: 0.19702\n",
      "Standard deviation of accuracy across 5 runs: 0.00045497252664309203\n",
      "\n",
      "Mean total confusion across 5 runs: 0.30151626666666664\n",
      "Standard deviation of total confusion across 5 runs: 0.01638281958061891\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2954242\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.01568106066175937\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.028010427293363522\n",
      "Standard deviation of per-task confusion across 5 runs: 0.004846384929706976\n",
      "\n",
      "Mean output bias across 5 runs: 0.78506\n",
      "Standard deviation of output bias across 5 runs: 0.0013557285864066026\n",
      "\n",
      "Mean embedding drift across 5 runs: 15.751250457763671\n",
      "Standard deviation of embedding drift across 5 runs: 0.7416157818675365\n",
      "\n",
      "Mean attention drift across 5 runs: 5.699284864540902e-06\n",
      "Standard deviation of attention drift across 5 runs: 9.740434110907527e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 52.986500508593956\n",
      "Standard deviation of attention spread across 5 runs: 2.679230640123725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = run_experiments(dataset='mnist', n_runs=5, full_CE=False)# baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.6791\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.6323\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.6481\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.6545\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.6707\n",
      "Mean accuracy across 5 runs: 0.65694\n",
      "Standard deviation of accuracy across 5 runs: 0.018517775244342945\n",
      "\n",
      "Mean total confusion across 5 runs: 0.26517653333333335\n",
      "Standard deviation of total confusion across 5 runs: 0.010413654283359608\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2631304666666667\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.010266379819044758\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.013770140119461387\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0011526582073460923\n",
      "\n",
      "Mean output bias across 5 runs: 0.32206\n",
      "Standard deviation of output bias across 5 runs: 0.014791991076254755\n",
      "\n",
      "Mean embedding drift across 5 runs: 8.187272357940675\n",
      "Standard deviation of embedding drift across 5 runs: 0.6386700107457765\n",
      "\n",
      "Mean attention drift across 5 runs: 1.535107676507678e-06\n",
      "Standard deviation of attention drift across 5 runs: 2.6983791136520205e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 48.671966139024626\n",
      "Standard deviation of attention spread across 5 runs: 1.1444316609156986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = run_experiments(dataset='mnist', n_runs=5, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1971\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1973\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1959\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.1973\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1981\n",
      "Mean accuracy across 5 runs: 0.19714\n",
      "Standard deviation of accuracy across 5 runs: 0.0007924645102463614\n",
      "\n",
      "Mean total confusion across 5 runs: 0.21946179999999998\n",
      "Standard deviation of total confusion across 5 runs: 0.009266260748303771\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2134478\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.0077643381223242445\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.023137949450076273\n",
      "Standard deviation of per-task confusion across 5 runs: 0.002563727416715811\n",
      "\n",
      "Mean output bias across 5 runs: 0.78676\n",
      "Standard deviation of output bias across 5 runs: 0.001772850811546226\n",
      "\n",
      "Mean embedding drift across 5 runs: 18.92416915893555\n",
      "Standard deviation of embedding drift across 5 runs: 0.8346943621446574\n",
      "\n",
      "Mean attention drift across 5 runs: 2.7388650126177126e-06\n",
      "Standard deviation of attention drift across 5 runs: 4.236520303926267e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 74.52603153191231\n",
      "Standard deviation of attention spread across 5 runs: 3.1970380253832777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex4 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1979\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1973\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1967\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.197\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1974\n",
      "Mean accuracy across 5 runs: 0.19726\n",
      "Standard deviation of accuracy across 5 runs: 0.00045055521304274376\n",
      "\n",
      "Mean total confusion across 5 runs: 0.2983267333333333\n",
      "Standard deviation of total confusion across 5 runs: 0.026113845311762588\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2877751333333333\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.023466952600767463\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.04347928433319726\n",
      "Standard deviation of per-task confusion across 5 runs: 0.010389888824512515\n",
      "\n",
      "Mean output bias across 5 runs: 0.78876\n",
      "Standard deviation of output bias across 5 runs: 0.00037815340802378457\n",
      "\n",
      "Mean embedding drift across 5 runs: 12.544556808471679\n",
      "Standard deviation of embedding drift across 5 runs: 0.2757958890689359\n",
      "\n",
      "Mean attention drift across 5 runs: 9.31783416565569e-06\n",
      "Standard deviation of attention drift across 5 runs: 1.6989221253487218e-06\n",
      "\n",
      "Mean attention spread across 5 runs: 54.07962192006978\n",
      "Standard deviation of attention spread across 5 runs: 1.4795080856465863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex5 = run_experiments(dataset='mnist', n_runs=5, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1974\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1942\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1973\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.1965\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1956\n",
      "Mean accuracy across 5 runs: 0.1962\n",
      "Standard deviation of accuracy across 5 runs: 0.0013322912594474182\n",
      "\n",
      "Mean total confusion across 5 runs: 0.2786928\n",
      "Standard deviation of total confusion across 5 runs: 0.012375638247514113\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2759276\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.012122452019565444\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.018358304031778457\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0022142367376584097\n",
      "\n",
      "Mean output bias across 5 runs: 0.78626\n",
      "Standard deviation of output bias across 5 runs: 0.0019346834366376297\n",
      "\n",
      "Mean embedding drift across 5 runs: 18.043492126464844\n",
      "Standard deviation of embedding drift across 5 runs: 1.1325006635331765\n",
      "\n",
      "Mean attention drift across 5 runs: 7.729867891168998e-06\n",
      "Standard deviation of attention drift across 5 runs: 5.153672626943934e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 50.188830216809514\n",
      "Standard deviation of attention spread across 5 runs: 1.2449296652130464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex7 = run_experiments(dataset='mnist', n_runs=5, optimiser_type='adam') # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1967\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1979\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1963\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.1976\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1976\n",
      "Mean accuracy across 5 runs: 0.19722\n",
      "Standard deviation of accuracy across 5 runs: 0.0006833739825307897\n",
      "\n",
      "Mean total confusion across 5 runs: 0.26263453333333336\n",
      "Standard deviation of total confusion across 5 runs: 0.022666385567619712\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2583906\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.02094580774469625\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.018907968423044322\n",
      "Standard deviation of per-task confusion across 5 runs: 0.005712710005354771\n",
      "\n",
      "Mean output bias across 5 runs: 0.78828\n",
      "Standard deviation of output bias across 5 runs: 0.0023477648945326632\n",
      "\n",
      "Mean embedding drift across 5 runs: 19.7469783782959\n",
      "Standard deviation of embedding drift across 5 runs: 1.3269651164639793\n",
      "\n",
      "Mean attention drift across 5 runs: 1.0933694984753583e-05\n",
      "Standard deviation of attention drift across 5 runs: 9.98412477845808e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 66.05666295991527\n",
      "Standard deviation of attention spread across 5 runs: 4.281695493758444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex8 = run_experiments_locally(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True) # all improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.8625\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.8783\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.8472\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.8676\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.8712\n",
      "Mean accuracy across 5 runs: 0.86536\n",
      "Standard deviation of accuracy across 5 runs: 0.011667604724192543\n",
      "\n",
      "Mean total confusion across 5 runs: 0.16521786666666669\n",
      "Standard deviation of total confusion across 5 runs: 0.007124483687335604\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.1628992\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.006968148325695195\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.010805132892886463\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0006999352199073621\n",
      "\n",
      "Mean output bias across 5 runs: 0.12109999999999999\n",
      "Standard deviation of output bias across 5 runs: 0.012728511303369314\n",
      "\n",
      "Mean embedding drift across 5 runs: 6.2946525573730465\n",
      "Standard deviation of embedding drift across 5 runs: 0.3712713159831253\n",
      "\n",
      "Mean attention drift across 5 runs: 8.825624336194423e-07\n",
      "Standard deviation of attention drift across 5 runs: 7.416524320821488e-08\n",
      "\n",
      "Mean attention spread across 5 runs: 58.02157103366236\n",
      "Standard deviation of attention spread across 5 runs: 1.3943544494278939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex9 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True) # all improvements without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.2068\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.2016\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1987\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.198\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.1991\n",
      "Mean accuracy across 5 runs: 0.20084\n",
      "Standard deviation of accuracy across 5 runs: 0.0035976381140965298\n",
      "\n",
      "Mean total confusion across 5 runs: 0.1945109333333333\n",
      "Standard deviation of total confusion across 5 runs: 0.012306290075043356\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.19035033333333334\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.011988576310156464\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.01745498423588679\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0023845686078281946\n",
      "\n",
      "Mean output bias across 5 runs: 0.78404\n",
      "Standard deviation of output bias across 5 runs: 0.0026922109872741895\n",
      "\n",
      "Mean embedding drift across 5 runs: 15.807488250732423\n",
      "Standard deviation of embedding drift across 5 runs: 0.9274291786163621\n",
      "\n",
      "Mean attention drift across 5 runs: 6.01162725144387e-06\n",
      "Standard deviation of attention drift across 5 runs: 4.996543926622673e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 59.40299514190308\n",
      "Standard deviation of attention spread across 5 runs: 2.7037222781477337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex10 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False) # all improvements without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.7781\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.718\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.7602\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.7721\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.7554\n",
      "Mean accuracy across 5 runs: 0.75676\n",
      "Standard deviation of accuracy across 5 runs: 0.023487933072111746\n",
      "\n",
      "Mean total confusion across 5 runs: 0.225098\n",
      "Standard deviation of total confusion across 5 runs: 0.007906878380386412\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.2237734666666667\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.00776819161567078\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.010401042402823463\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0010261922031812266\n",
      "\n",
      "Mean output bias across 5 runs: 0.22828\n",
      "Standard deviation of output bias across 5 runs: 0.02330272516252126\n",
      "\n",
      "Mean embedding drift across 5 runs: 5.013447093963623\n",
      "Standard deviation of embedding drift across 5 runs: 0.10689131038691713\n",
      "\n",
      "Mean attention drift across 5 runs: 9.471835055701329e-07\n",
      "Standard deviation of attention drift across 5 runs: 6.157643266855094e-08\n",
      "\n",
      "Mean attention spread across 5 runs: 48.14350581825227\n",
      "Standard deviation of attention spread across 5 runs: 1.496594905633051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex11 = run_experiments(dataset='mnist', n_runs=5, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True) # all improvements without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.8262\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.7848\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.7836\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.825\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.7412\n",
      "Mean accuracy across 5 runs: 0.79216\n",
      "Standard deviation of accuracy across 5 runs: 0.03521914252221369\n",
      "\n",
      "Mean total confusion across 5 runs: 0.20879066666666665\n",
      "Standard deviation of total confusion across 5 runs: 0.007163731619918676\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.20517813333333332\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.006934348926419376\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.01508101297714759\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0012527355734396797\n",
      "\n",
      "Mean output bias across 5 runs: 0.18968000000000002\n",
      "Standard deviation of output bias across 5 runs: 0.03315692989406592\n",
      "\n",
      "Mean embedding drift across 5 runs: 8.123602676391602\n",
      "Standard deviation of embedding drift across 5 runs: 0.8998637729476626\n",
      "\n",
      "Mean attention drift across 5 runs: 6.007575386888514e-07\n",
      "Standard deviation of attention drift across 5 runs: 2.934392530225201e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 73.58439556498722\n",
      "Standard deviation of attention spread across 5 runs: 5.51560018326913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex12 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True) # all improvements without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.6349\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.7466\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.7567\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.6567\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.6589\n",
      "Mean accuracy across 5 runs: 0.69076\n",
      "Standard deviation of accuracy across 5 runs: 0.056483785283920215\n",
      "\n",
      "Mean total confusion across 5 runs: 0.1931168\n",
      "Standard deviation of total confusion across 5 runs: 0.01320736273531631\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.19061653333333334\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.013116010363928017\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.013589046252764705\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0013523568370232314\n",
      "\n",
      "Mean output bias across 5 runs: 0.29632\n",
      "Standard deviation of output bias across 5 runs: 0.05571572488983698\n",
      "\n",
      "Mean embedding drift across 5 runs: 6.830794620513916\n",
      "Standard deviation of embedding drift across 5 runs: 0.28650523230271374\n",
      "\n",
      "Mean attention drift across 5 runs: 2.2501782347604858e-06\n",
      "Standard deviation of attention drift across 5 runs: 3.7935774182662325e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 65.34201916755158\n",
      "Standard deviation of attention spread across 5 runs: 1.746812637596245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex14 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam') # all improvements with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.7221\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.7089\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.7229\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.6543\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.6454\n",
      "Mean accuracy across 5 runs: 0.69072\n",
      "Standard deviation of accuracy across 5 runs: 0.03785197484940515\n",
      "\n",
      "Mean total confusion across 5 runs: 0.16659393333333333\n",
      "Standard deviation of total confusion across 5 runs: 0.008450156535039282\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.1653022\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.008425832272112783\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.00689000241771053\n",
      "Standard deviation of per-task confusion across 5 runs: 0.0008540630579552725\n",
      "\n",
      "Mean output bias across 5 runs: 0.29536\n",
      "Standard deviation of output bias across 5 runs: 0.03750050666324391\n",
      "\n",
      "Mean embedding drift across 5 runs: 9.341233158111573\n",
      "Standard deviation of embedding drift across 5 runs: 1.3365390083716817\n",
      "\n",
      "Mean attention drift across 5 runs: 3.4144441280031843e-06\n",
      "Standard deviation of attention drift across 5 runs: 6.319566478752158e-07\n",
      "\n",
      "Mean attention spread across 5 runs: 59.47461964455886\n",
      "Standard deviation of attention spread across 5 runs: 4.741765496177308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex15 = run_experiments(dataset='mnist', n_runs=5, with_dropout=True, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.9905\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.9915\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.9913\n",
      "Finished run 4.\n",
      "Run 3 finished with accuracy 0.9906\n",
      "Finished run 5.\n",
      "Run 4 finished with accuracy 0.9913\n",
      "Mean accuracy across 5 runs: 0.99104\n",
      "Standard deviation of accuracy across 5 runs: 0.00045607017003963297\n",
      "\n",
      "Mean total confusion across 5 runs: 0.049904933333333325\n",
      "Standard deviation of total confusion across 5 runs: 0.002843215036616902\n",
      "\n",
      "Mean intra-phase confusion across 5 runs: 0.0\n",
      "Standard deviation of intra-phase confusion across 5 runs: 0.0\n",
      "\n",
      "Mean per-task confusion across 5 runs: 0.049904933333333325\n",
      "Standard deviation of per-task confusion across 5 runs: 0.002843215036616902\n",
      "\n",
      "Mean output bias across 5 runs: 0\n",
      "Standard deviation of output bias across 5 runs: 0.0\n",
      "\n",
      "Mean embedding drift across 5 runs: 6.624188972637057e-06\n",
      "Standard deviation of embedding drift across 5 runs: 2.3252230501740707e-07\n",
      "\n",
      "Mean attention drift across 5 runs: 1.321890417614269e-20\n",
      "Standard deviation of attention drift across 5 runs: 7.2243059522384505e-22\n",
      "\n",
      "Mean attention spread across 5 runs: 51.9256250812149\n",
      "Standard deviation of attention spread across 5 runs: 0.9390238242333607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for CIFAR10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_1 = run_experiments(dataset='cifar10', n_runs=3) # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1879\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1921\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1862\n",
      "Mean accuracy across 3 runs: 0.18873333333333334\n",
      "Standard deviation of accuracy across 3 runs: 0.0030369941279714866\n",
      "\n",
      "Mean total confusion across 3 runs: 0.8150898888888889\n",
      "Standard deviation of total confusion across 3 runs: 0.00590723881101571\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.735893\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.006888937323306408\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.35517077777777784\n",
      "Standard deviation of per-task confusion across 3 runs: 0.013072628598773894\n",
      "\n",
      "Mean output bias across 3 runs: 0.13786666666666667\n",
      "Standard deviation of output bias across 3 runs: 0.027837085575421364\n",
      "\n",
      "Mean embedding drift across 3 runs: 5.611140727996826\n",
      "Standard deviation of embedding drift across 3 runs: 0.42372610870980176\n",
      "\n",
      "Mean attention drift across 3 runs: 3.426761663301175e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.1009408349046692e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 132.42196681501596\n",
      "Standard deviation of attention spread across 3 runs: 1.9320842639753253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_2 = run_experiments(dataset='cifar10', n_runs=3, full_CE=False) # baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1581\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0577\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1615\n",
      "Mean accuracy across 3 runs: 0.12576666666666667\n",
      "Standard deviation of accuracy across 3 runs: 0.058971970743170295\n",
      "\n",
      "Mean total confusion across 3 runs: 0.8136176666666667\n",
      "Standard deviation of total confusion across 3 runs: 0.0011870364124340572\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7345164444444444\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.005755544827317365\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.348965\n",
      "Standard deviation of per-task confusion across 3 runs: 0.007998210862436688\n",
      "\n",
      "Mean output bias across 3 runs: 0.25053333333333333\n",
      "Standard deviation of output bias across 3 runs: 0.07827888178387153\n",
      "\n",
      "Mean embedding drift across 3 runs: 3.3491338888804116\n",
      "Standard deviation of embedding drift across 3 runs: 0.4337011301139496\n",
      "\n",
      "Mean attention drift across 3 runs: 3.1004676443776226e-07\n",
      "Standard deviation of attention drift across 3 runs: 4.043118261641913e-09\n",
      "\n",
      "Mean attention spread across 3 runs: 130.11555153384745\n",
      "Standard deviation of attention spread across 3 runs: 3.1534063902566083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_3 = run_experiments(dataset='cifar10', n_runs=3, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1896\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1903\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.189\n",
      "Mean accuracy across 3 runs: 0.18963333333333332\n",
      "Standard deviation of accuracy across 3 runs: 0.0006506407098647691\n",
      "\n",
      "Mean total confusion across 3 runs: 0.7954076666666667\n",
      "Standard deviation of total confusion across 3 runs: 0.012795435058384411\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7152497777777779\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.010628348833470129\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.3371353333333333\n",
      "Standard deviation of per-task confusion across 3 runs: 0.009632010076360584\n",
      "\n",
      "Mean output bias across 3 runs: 0.21576666666666666\n",
      "Standard deviation of output bias across 3 runs: 0.028889675202974047\n",
      "\n",
      "Mean embedding drift across 3 runs: 7.078327337900798\n",
      "Standard deviation of embedding drift across 3 runs: 0.12330433918255805\n",
      "\n",
      "Mean attention drift across 3 runs: 2.899680300302521e-07\n",
      "Standard deviation of attention drift across 3 runs: 4.0253767188010814e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 132.53426376385156\n",
      "Standard deviation of attention spread across 3 runs: 4.264037614149459\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_4 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1903\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1898\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1926\n",
      "Mean accuracy across 3 runs: 0.1909\n",
      "Standard deviation of accuracy across 3 runs: 0.001493318452306806\n",
      "\n",
      "Mean total confusion across 3 runs: 0.7926706666666666\n",
      "Standard deviation of total confusion across 3 runs: 0.013702840609807063\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7151139999999999\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.011003860246901203\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.3405243333333334\n",
      "Standard deviation of per-task confusion across 3 runs: 0.013260845779126543\n",
      "\n",
      "Mean output bias across 3 runs: 0.19856666666666667\n",
      "Standard deviation of output bias across 3 runs: 0.04019966832367319\n",
      "\n",
      "Mean embedding drift across 3 runs: 4.00794514020284\n",
      "Standard deviation of embedding drift across 3 runs: 0.07444926386411467\n",
      "\n",
      "Mean attention drift across 3 runs: 3.5139745852272137e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.0432673149540153e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 127.12995169440379\n",
      "Standard deviation of attention spread across 3 runs: 0.20820225547313828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_5 = run_experiments(dataset='cifar10', n_runs=3, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1909\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1909\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1914\n",
      "Mean accuracy across 3 runs: 0.19106666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.00028867513459481317\n",
      "\n",
      "Mean total confusion across 3 runs: 0.7290466666666666\n",
      "Standard deviation of total confusion across 3 runs: 0.013700385773157414\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6753583333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.013727380198388574\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.23976144444444442\n",
      "Standard deviation of per-task confusion across 3 runs: 0.016109701191564074\n",
      "\n",
      "Mean output bias across 3 runs: 0.31960000000000005\n",
      "Standard deviation of output bias across 3 runs: 0.023900627606822412\n",
      "\n",
      "Mean embedding drift across 3 runs: 7.149629592895508\n",
      "Standard deviation of embedding drift across 3 runs: 0.2568053278392342\n",
      "\n",
      "Mean attention drift across 3 runs: 2.231473689681945e-07\n",
      "Standard deviation of attention drift across 3 runs: 2.50689495227343e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 130.85103780627782\n",
      "Standard deviation of attention spread across 3 runs: 0.9813344286942421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_7 = run_experiments(dataset='cifar10', n_runs=3, optimiser_type='adam', lr=0.001) # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1884\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1884\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.186\n",
      "Mean accuracy across 3 runs: 0.18760000000000002\n",
      "Standard deviation of accuracy across 3 runs: 0.0013856406460551094\n",
      "\n",
      "Mean total confusion across 3 runs: 0.8075774444444445\n",
      "Standard deviation of total confusion across 3 runs: 0.006486076457675674\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7307914444444444\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0028884119499463365\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.3462801111111111\n",
      "Standard deviation of per-task confusion across 3 runs: 0.011423664523617113\n",
      "\n",
      "Mean output bias across 3 runs: 0.1556\n",
      "Standard deviation of output bias across 3 runs: 0.04400136361523356\n",
      "\n",
      "Mean embedding drift across 3 runs: 26.946285247802734\n",
      "Standard deviation of embedding drift across 3 runs: 10.425892047866796\n",
      "\n",
      "Mean attention drift across 3 runs: 3.904787418643233e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.2476308580437087e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 146.70146571375528\n",
      "Standard deviation of attention spread across 3 runs: 4.83112277324964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_8 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # all improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.4094\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.3506\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.411\n",
      "Mean accuracy across 3 runs: 0.3903333333333333\n",
      "Standard deviation of accuracy across 3 runs: 0.034419374389046235\n",
      "\n",
      "Mean total confusion across 3 runs: 0.6786732222222222\n",
      "Standard deviation of total confusion across 3 runs: 0.008851295387514566\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6425097777777777\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.009202880408590311\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.16869922222222222\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0013186683659128485\n",
      "\n",
      "Mean output bias across 3 runs: 0.185\n",
      "Standard deviation of output bias across 3 runs: 0.027904838290160373\n",
      "\n",
      "Mean embedding drift across 3 runs: 2.7267093658447266\n",
      "Standard deviation of embedding drift across 3 runs: 0.18285992033846996\n",
      "\n",
      "Mean attention drift across 3 runs: 1.351646285622602e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.1591251611944215e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 129.74971134092542\n",
      "Standard deviation of attention spread across 3 runs: 2.9363675960024795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_9 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True, optimiser_type='sgd') # all improvements without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1924\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1923\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1932\n",
      "Mean accuracy across 3 runs: 0.19263333333333332\n",
      "Standard deviation of accuracy across 3 runs: 0.0004932882862316341\n",
      "\n",
      "Mean total confusion across 3 runs: 0.6966635555555556\n",
      "Standard deviation of total confusion across 3 runs: 0.009691097554705303\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6490783333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.007695207195246763\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.21338422222222225\n",
      "Standard deviation of per-task confusion across 3 runs: 0.02077878608456589\n",
      "\n",
      "Mean output bias across 3 runs: 0.36346666666666666\n",
      "Standard deviation of output bias across 3 runs: 0.019119710597530808\n",
      "\n",
      "Mean embedding drift across 3 runs: 6.24628225962321\n",
      "Standard deviation of embedding drift across 3 runs: 0.6229272377467012\n",
      "\n",
      "Mean attention drift across 3 runs: 2.484807036566394e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.2423233737355766e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 132.65159524900648\n",
      "Standard deviation of attention spread across 3 runs: 2.002175789328639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_10 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False, optimiser_type='sgd') # all improvements without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.3335\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.3889\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.3643\n",
      "Mean accuracy across 3 runs: 0.36223333333333335\n",
      "Standard deviation of accuracy across 3 runs: 0.027757761677291874\n",
      "\n",
      "Mean total confusion across 3 runs: 0.6878068888888889\n",
      "Standard deviation of total confusion across 3 runs: 0.0208423163895351\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6543283333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.018454712942166742\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.16579566666666667\n",
      "Standard deviation of per-task confusion across 3 runs: 0.009867631535029639\n",
      "\n",
      "Mean output bias across 3 runs: 0.2186333333333333\n",
      "Standard deviation of output bias across 3 runs: 0.007200231477760552\n",
      "\n",
      "Mean embedding drift across 3 runs: 2.03570028146108\n",
      "Standard deviation of embedding drift across 3 runs: 0.2500934602964982\n",
      "\n",
      "Mean attention drift across 3 runs: 1.2656743829744255e-07\n",
      "Standard deviation of attention drift across 3 runs: 1.3952044952026904e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 130.12667747005887\n",
      "Standard deviation of attention spread across 3 runs: 1.0768311872451932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_11 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # all improvements without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.4584\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.4085\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.4875\n",
      "Mean accuracy across 3 runs: 0.4514666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.03995376494566356\n",
      "\n",
      "Mean total confusion across 3 runs: 0.6546418888888889\n",
      "Standard deviation of total confusion across 3 runs: 0.005383163437291571\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6179250000000001\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0024396887779660195\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.1690621111111111\n",
      "Standard deviation of per-task confusion across 3 runs: 0.01101647221882524\n",
      "\n",
      "Mean output bias across 3 runs: 0.1623666666666667\n",
      "Standard deviation of output bias across 3 runs: 0.03730017873058159\n",
      "\n",
      "Mean embedding drift across 3 runs: 4.669615427652995\n",
      "Standard deviation of embedding drift across 3 runs: 0.2838798655521294\n",
      "\n",
      "Mean attention drift across 3 runs: 6.844182714947541e-08\n",
      "Standard deviation of attention drift across 3 runs: 1.0016457842603275e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 134.4408815403408\n",
      "Standard deviation of attention spread across 3 runs: 1.0188902222492495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_12 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True, optimiser_type='sgd') # all improvements without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1616\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0545\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0549\n",
      "Mean accuracy across 3 runs: 0.09033333333333333\n",
      "Standard deviation of accuracy across 3 runs: 0.06171906782618588\n",
      "\n",
      "Mean total confusion across 3 runs: 0.8054283333333333\n",
      "Standard deviation of total confusion across 3 runs: 0.004481763802095938\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7300105555555556\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.004231749839452171\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.3399215555555556\n",
      "Standard deviation of per-task confusion across 3 runs: 0.01223262827365733\n",
      "\n",
      "Mean output bias across 3 runs: 0.2692333333333333\n",
      "Standard deviation of output bias across 3 runs: 0.09019120430138038\n",
      "\n",
      "Mean embedding drift across 3 runs: 3.1476405461629233\n",
      "Standard deviation of embedding drift across 3 runs: 0.3724409874625537\n",
      "\n",
      "Mean attention drift across 3 runs: 3.0758886688389e-07\n",
      "Standard deviation of attention drift across 3 runs: 2.6599563379706748e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 128.70412307832507\n",
      "Standard deviation of attention spread across 3 runs: 2.771522718586321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_14 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam', lr=0.001) # all improvements with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.3494\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.3875\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.3646\n",
      "Mean accuracy across 3 runs: 0.36716666666666664\n",
      "Standard deviation of accuracy across 3 runs: 0.0191792422512813\n",
      "\n",
      "Mean total confusion across 3 runs: 0.7250651111111112\n",
      "Standard deviation of total confusion across 3 runs: 0.007741162712935783\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6788436666666666\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.007391588582826914\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.21498788888888887\n",
      "Standard deviation of per-task confusion across 3 runs: 0.005980634120348888\n",
      "\n",
      "Mean output bias across 3 runs: 0.1579\n",
      "Standard deviation of output bias across 3 runs: 0.018730456481356787\n",
      "\n",
      "Mean embedding drift across 3 runs: 10.01424757639567\n",
      "Standard deviation of embedding drift across 3 runs: 0.9237363654591716\n",
      "\n",
      "Mean attention drift across 3 runs: 3.1909643724456296e-07\n",
      "Standard deviation of attention drift across 3 runs: 9.593649063369558e-09\n",
      "\n",
      "Mean attention spread across 3 runs: 142.99666618041985\n",
      "Standard deviation of attention spread across 3 runs: 1.635016715399503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_15 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.8198\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.8164\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.8237\n",
      "Mean accuracy across 3 runs: 0.8199666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.003652852766446143\n",
      "\n",
      "Mean total confusion across 3 runs: 0.29480211111111115\n",
      "Standard deviation of total confusion across 3 runs: 0.004794796141342918\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.0\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.29480211111111115\n",
      "Standard deviation of per-task confusion across 3 runs: 0.004794796141342918\n",
      "\n",
      "Mean output bias across 3 runs: 0\n",
      "Standard deviation of output bias across 3 runs: 0.0\n",
      "\n",
      "Mean embedding drift across 3 runs: 2.9902341793786036e-06\n",
      "Standard deviation of embedding drift across 3 runs: 9.015204393919827e-08\n",
      "\n",
      "Mean attention drift across 3 runs: 0.0\n",
      "Standard deviation of attention drift across 3 runs: 0.0\n",
      "\n",
      "Mean attention spread across 3 runs: 124.12653327064504\n",
      "Standard deviation of attention spread across 3 runs: 1.384544717364359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_15_2 = run_experiments(dataset='cifar10', n_runs=3, with_dropout=False, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.7772\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.7882\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.7725\n",
      "Mean accuracy across 3 runs: 0.7793\n",
      "Standard deviation of accuracy across 3 runs: 0.008057915363169332\n",
      "\n",
      "Mean total confusion across 3 runs: 0.4202355555555556\n",
      "Standard deviation of total confusion across 3 runs: 0.02317752783608707\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.0\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.4202355555555556\n",
      "Standard deviation of per-task confusion across 3 runs: 0.02317752783608707\n",
      "\n",
      "Mean output bias across 3 runs: 0\n",
      "Standard deviation of output bias across 3 runs: 0.0\n",
      "\n",
      "Mean embedding drift across 3 runs: 5.864368328426887e-06\n",
      "Standard deviation of embedding drift across 3 runs: 6.625277733125135e-07\n",
      "\n",
      "Mean attention drift across 3 runs: 0.0\n",
      "Standard deviation of attention drift across 3 runs: 0.0\n",
      "\n",
      "Mean attention spread across 3 runs: 134.20428144412566\n",
      "Standard deviation of attention spread across 3 runs: 0.25371332578099925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_15_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "ex_cf_16 = run_experiments(dataset='cifar10', n_runs=3, kd_loss=1, full_CE=False) # SPECIAL CASE (WILL NOT ADD TO TABLE IN REPORT)\n",
    "# use this case for analysis of why special CE doesn't work in cifar10. Problem is domain shift, this shows that kd_loss stabilizes it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.4343\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.4133\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.3978\n",
      "Mean accuracy across 3 runs: 0.41513333333333335\n",
      "Standard deviation of accuracy across 3 runs: 0.0183189337389853\n",
      "\n",
      "Mean total confusion across 3 runs: 0.6591074444444444\n",
      "Standard deviation of total confusion across 3 runs: 0.0010595532252024884\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.6233385555555556\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.002438204287615822\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.16436333333333333\n",
      "Standard deviation of per-task confusion across 3 runs: 0.006785838497275858\n",
      "\n",
      "Mean output bias across 3 runs: 0.18649999999999997\n",
      "Standard deviation of output bias across 3 runs: 0.024874283909290733\n",
      "\n",
      "Mean embedding drift across 3 runs: 4.089497168858846\n",
      "Standard deviation of embedding drift across 3 runs: 0.5539006621653072\n",
      "\n",
      "Mean attention drift across 3 runs: 8.705355532144439e-08\n",
      "Standard deviation of attention drift across 3 runs: 1.0483556438170626e-08\n",
      "\n",
      "Mean attention spread across 3 runs: 135.5245984281752\n",
      "Standard deviation of attention spread across 3 runs: 2.95588116755427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(ex_cf_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for tiny imagenet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_1 = run_experiments(dataset='tiny_imagenet', n_runs=3) # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0634\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0628\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0594\n",
      "Mean accuracy across 3 runs: 0.06186666666666667\n",
      "Standard deviation of accuracy across 3 runs: 0.0021571586249817887\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9915338888888888\n",
      "Standard deviation of total confusion across 3 runs: 7.065513532751243e-05\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7913187777777778\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.00035209694582493447\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9691908888888889\n",
      "Standard deviation of per-task confusion across 3 runs: 0.00022921056145273696\n",
      "\n",
      "Mean output bias across 3 runs: 0.050666666666666665\n",
      "Standard deviation of output bias across 3 runs: 0.005550075074567313\n",
      "\n",
      "Mean embedding drift across 3 runs: 31.5178165435791\n",
      "Standard deviation of embedding drift across 3 runs: 0.8299934470172012\n",
      "\n",
      "Mean attention drift across 3 runs: 2.513306655880972e-08\n",
      "Standard deviation of attention drift across 3 runs: 8.629280393459626e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 507.0720177096896\n",
      "Standard deviation of attention spread across 3 runs: 9.921712084071464\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_2 = run_experiments(dataset='tiny_imagenet', n_runs=3, full_CE=False) # baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0907\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0767\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0877\n",
      "Mean accuracy across 3 runs: 0.08503333333333334\n",
      "Standard deviation of accuracy across 3 runs: 0.007371114795831992\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9919312222222222\n",
      "Standard deviation of total confusion across 3 runs: 8.691588100206384e-05\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7929924444444444\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0003788705925852719\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9698965555555555\n",
      "Standard deviation of per-task confusion across 3 runs: 3.398420112231607e-05\n",
      "\n",
      "Mean output bias across 3 runs: 0.0315\n",
      "Standard deviation of output bias across 3 runs: 0.009183136719008379\n",
      "\n",
      "Mean embedding drift across 3 runs: 28.166884740193684\n",
      "Standard deviation of embedding drift across 3 runs: 0.8096294696119921\n",
      "\n",
      "Mean attention drift across 3 runs: 2.139450292889163e-08\n",
      "Standard deviation of attention drift across 3 runs: 8.851252735915092e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 492.88505808647994\n",
      "Standard deviation of attention spread across 3 runs: 8.790610680683566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_3 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0618\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.065\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0681\n",
      "Mean accuracy across 3 runs: 0.06496666666666667\n",
      "Standard deviation of accuracy across 3 runs: 0.0031501322723551327\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9915974444444444\n",
      "Standard deviation of total confusion across 3 runs: 0.00020883495166529553\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7915796666666667\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0007766400567687742\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9691761111111111\n",
      "Standard deviation of per-task confusion across 3 runs: 0.00029397474066351605\n",
      "\n",
      "Mean output bias across 3 runs: 0.048600000000000004\n",
      "Standard deviation of output bias across 3 runs: 0.0019974984355438197\n",
      "\n",
      "Mean embedding drift across 3 runs: 30.93061065673828\n",
      "Standard deviation of embedding drift across 3 runs: 1.1639619282451465\n",
      "\n",
      "Mean attention drift across 3 runs: 2.6318439145178726e-08\n",
      "Standard deviation of attention drift across 3 runs: 7.991573461759634e-11\n",
      "\n",
      "Mean attention spread across 3 runs: 494.69226207241496\n",
      "Standard deviation of attention spread across 3 runs: 5.350334775881695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_4 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0931\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0926\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0909\n",
      "Mean accuracy across 3 runs: 0.0922\n",
      "Standard deviation of accuracy across 3 runs: 0.0011532562594670837\n",
      "\n",
      "Mean total confusion across 3 runs: 0.983536\n",
      "Standard deviation of total confusion across 3 runs: 0.0005849770175922516\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7669123333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.002596272991124836\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9555955555555555\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0005886268704303028\n",
      "\n",
      "Mean output bias across 3 runs: 0.14406666666666665\n",
      "Standard deviation of output bias across 3 runs: 0.0028041635710730774\n",
      "\n",
      "Mean embedding drift across 3 runs: 9.662531534830729\n",
      "Standard deviation of embedding drift across 3 runs: 0.38065871027636633\n",
      "\n",
      "Mean attention drift across 3 runs: 2.2121093413722073e-08\n",
      "Standard deviation of attention drift across 3 runs: 1.510061168251746e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 540.5180328202988\n",
      "Standard deviation of attention spread across 3 runs: 3.7244870719560805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_5 = run_experiments(dataset='tiny_imagenet', n_runs=3, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.073\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0721\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0748\n",
      "Mean accuracy across 3 runs: 0.0733\n",
      "Standard deviation of accuracy across 3 runs: 0.0013747727084867567\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9870364444444444\n",
      "Standard deviation of total confusion across 3 runs: 0.0004383674680414145\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7816603333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0010330113476842643\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.960741888888889\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0005856598684233329\n",
      "\n",
      "Mean output bias across 3 runs: 0.09\n",
      "Standard deviation of output bias across 3 runs: 0.0071526218968990625\n",
      "\n",
      "Mean embedding drift across 3 runs: 18.61656316121419\n",
      "Standard deviation of embedding drift across 3 runs: 0.5844481796040305\n",
      "\n",
      "Mean attention drift across 3 runs: 1.4041124999501313e-08\n",
      "Standard deviation of attention drift across 3 runs: 6.4388101436063e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 485.30915491604304\n",
      "Standard deviation of attention spread across 3 runs: 4.896483871170713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_7 = run_experiments(dataset='tiny_imagenet', n_runs=3, optimiser_type='adam', lr=1e-5) # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0642\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0691\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0673\n",
      "Mean accuracy across 3 runs: 0.06686666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.002478574859336175\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9847037777777777\n",
      "Standard deviation of total confusion across 3 runs: 0.0003946498213371984\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7739423333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0011745263347882576\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9565204444444445\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0006138018440047692\n",
      "\n",
      "Mean output bias across 3 runs: 0.04523333333333334\n",
      "Standard deviation of output bias across 3 runs: 0.0065248243909957655\n",
      "\n",
      "Mean embedding drift across 3 runs: 166.10789998372397\n",
      "Standard deviation of embedding drift across 3 runs: 13.98068507086361\n",
      "\n",
      "Mean attention drift across 3 runs: 2.3109940638018264e-08\n",
      "Standard deviation of attention drift across 3 runs: 8.27979183366742e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 446.83287874688017\n",
      "Standard deviation of attention spread across 3 runs: 5.1707668349363916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_8 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True) # all improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1852\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1793\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1664\n",
      "Mean accuracy across 3 runs: 0.17696666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.009614745619793245\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9836961111111111\n",
      "Standard deviation of total confusion across 3 runs: 0.00013817232933040937\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7741814444444445\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0006395016578324263\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9559936666666667\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0002571076298622276\n",
      "\n",
      "Mean output bias across 3 runs: 0.07853333333333333\n",
      "Standard deviation of output bias across 3 runs: 0.006536308846232205\n",
      "\n",
      "Mean embedding drift across 3 runs: 7.189832051595052\n",
      "Standard deviation of embedding drift across 3 runs: 0.27527592087940633\n",
      "\n",
      "Mean attention drift across 3 runs: 1.545933216156037e-08\n",
      "Standard deviation of attention drift across 3 runs: 3.0588860315494e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 490.4306316438466\n",
      "Standard deviation of attention spread across 3 runs: 3.9955407092717565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_9 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True) # all improvements without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.0886\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.0905\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.0815\n",
      "Mean accuracy across 3 runs: 0.08686666666666666\n",
      "Standard deviation of accuracy across 3 runs: 0.004743767841424505\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9821005555555555\n",
      "Standard deviation of total confusion across 3 runs: 0.0007761556497202294\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7707377777777779\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.001749275289094585\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9528783333333333\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0010631142930090274\n",
      "\n",
      "Mean output bias across 3 runs: 0.15813333333333332\n",
      "Standard deviation of output bias across 3 runs: 0.00829236596716121\n",
      "\n",
      "Mean embedding drift across 3 runs: 9.898040135701498\n",
      "Standard deviation of embedding drift across 3 runs: 0.2241771029562697\n",
      "\n",
      "Mean attention drift across 3 runs: 1.848128587738825e-08\n",
      "Standard deviation of attention drift across 3 runs: 1.3700126095513316e-09\n",
      "\n",
      "Mean attention spread across 3 runs: 492.7888025689022\n",
      "Standard deviation of attention spread across 3 runs: 1.1083626933381454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_10 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False) # all improvements without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1719\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1806\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1757\n",
      "Mean accuracy across 3 runs: 0.17606666666666668\n",
      "Standard deviation of accuracy across 3 runs: 0.004361574639202383\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9841695555555555\n",
      "Standard deviation of total confusion across 3 runs: 0.00030854215151133487\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7761391111111111\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0008763111023763833\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9566862222222222\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0006991716792298495\n",
      "\n",
      "Mean output bias across 3 runs: 0.07166666666666667\n",
      "Standard deviation of output bias across 3 runs: 0.01032537327815966\n",
      "\n",
      "Mean embedding drift across 3 runs: 6.84524933497111\n",
      "Standard deviation of embedding drift across 3 runs: 0.09448083905415895\n",
      "\n",
      "Mean attention drift across 3 runs: 1.3168940280094965e-08\n",
      "Standard deviation of attention drift across 3 runs: 1.758565260494219e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 492.2450869720456\n",
      "Standard deviation of attention spread across 3 runs: 2.266112675863758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_11 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True) # all improvements without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ex_11[2] = ex_parallel.submit(run_experiment,dataset='tiny_imagenet', with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SlurmJob<job_id=12304548, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=12304549, task_id=0, state=\"COMPLETED\">,\n",
       " SlurmJob<job_id=12304614, task_id=0, state=\"COMPLETED\">]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_ex_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1409\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1459\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1458\n",
      "Mean accuracy across 3 runs: 0.1442\n",
      "Standard deviation of accuracy across 3 runs: 0.002858321185591296\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9885244444444444\n",
      "Standard deviation of total confusion across 3 runs: 0.00030243021845881946\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7852413333333333\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.000600662967062231\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9634887777777779\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0005432581065850459\n",
      "\n",
      "Mean output bias across 3 runs: 0.022866666666666664\n",
      "Standard deviation of output bias across 3 runs: 0.004488132499529549\n",
      "\n",
      "Mean embedding drift across 3 runs: 10.45455805460612\n",
      "Standard deviation of embedding drift across 3 runs: 0.210280833388122\n",
      "\n",
      "Mean attention drift across 3 runs: 9.314878123511949e-09\n",
      "Standard deviation of attention drift across 3 runs: 3.428962428566917e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 462.6249910319857\n",
      "Standard deviation of attention spread across 3 runs: 5.562683306795427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_12 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True) # all improvements without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1431\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1426\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.1513\n",
      "Mean accuracy across 3 runs: 0.14566666666666667\n",
      "Standard deviation of accuracy across 3 runs: 0.004885011088353153\n",
      "\n",
      "Mean total confusion across 3 runs: 0.983294\n",
      "Standard deviation of total confusion across 3 runs: 0.0006924769550918922\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7717032222222222\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0013501539144085153\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9558331111111111\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0010580228065875225\n",
      "\n",
      "Mean output bias across 3 runs: 0.10443333333333334\n",
      "Standard deviation of output bias across 3 runs: 0.011602729563914404\n",
      "\n",
      "Mean embedding drift across 3 runs: 8.168802579243978\n",
      "Standard deviation of embedding drift across 3 runs: 0.25334120069607824\n",
      "\n",
      "Mean attention drift across 3 runs: 2.0936146238910897e-08\n",
      "Standard deviation of attention drift across 3 runs: 4.788752953091488e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 509.119127566359\n",
      "Standard deviation of attention spread across 3 runs: 5.033644608280517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_13 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam', lr=1e-5) # all improvements with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.1281\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.1291\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.12\n",
      "Mean accuracy across 3 runs: 0.12573333333333334\n",
      "Standard deviation of accuracy across 3 runs: 0.004990323970779183\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9822547777777778\n",
      "Standard deviation of total confusion across 3 runs: 0.0008190082304113691\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.7696024444444445\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0031863844075366706\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9528646666666667\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0014558943795635107\n",
      "\n",
      "Mean output bias across 3 runs: 0.07866666666666668\n",
      "Standard deviation of output bias across 3 runs: 0.004168133075290815\n",
      "\n",
      "Mean embedding drift across 3 runs: 19.478856404622395\n",
      "Standard deviation of embedding drift across 3 runs: 1.8317047127459407\n",
      "\n",
      "Mean attention drift across 3 runs: 9.389580646579355e-09\n",
      "Standard deviation of attention drift across 3 runs: 7.763563495311542e-10\n",
      "\n",
      "Mean attention spread across 3 runs: 473.1843091634115\n",
      "Standard deviation of attention spread across 3 runs: 2.271664930064375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n"
     ]
    }
   ],
   "source": [
    "in_ex_14 = run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run 1.\n",
      "Run 0 finished with accuracy 0.3287\n",
      "Finished run 2.\n",
      "Run 1 finished with accuracy 0.3324\n",
      "Finished run 3.\n",
      "Run 2 finished with accuracy 0.3397\n",
      "Mean accuracy across 3 runs: 0.3336\n",
      "Standard deviation of accuracy across 3 runs: 0.0055973207876626185\n",
      "\n",
      "Mean total confusion across 3 runs: 0.9785554444444444\n",
      "Standard deviation of total confusion across 3 runs: 0.0005464743903050235\n",
      "\n",
      "Mean intra-phase confusion across 3 runs: 0.0\n",
      "Standard deviation of intra-phase confusion across 3 runs: 0.0\n",
      "\n",
      "Mean per-task confusion across 3 runs: 0.9785554444444444\n",
      "Standard deviation of per-task confusion across 3 runs: 0.0005464743903050235\n",
      "\n",
      "Mean output bias across 3 runs: 0\n",
      "Standard deviation of output bias across 3 runs: 0.0\n",
      "\n",
      "Mean embedding drift across 3 runs: 0.00012565715587697923\n",
      "Standard deviation of embedding drift across 3 runs: 2.0208399336555662e-05\n",
      "\n",
      "Mean attention drift across 3 runs: 0.0\n",
      "Standard deviation of attention drift across 3 runs: 0.0\n",
      "\n",
      "Mean attention spread across 3 runs: 522.7294301730694\n",
      "Standard deviation of attention spread across 3 runs: 1.8541954105661194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_performance(in_ex_14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
