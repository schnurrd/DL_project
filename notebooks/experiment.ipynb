{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "torch.cuda.empty_cache()\n",
    "import sys\n",
    "sys.path.append('./../src')\n",
    "import globals\n",
    "from model import MnistCNN, TinyImageNetCNN, Cifar10CNN\n",
    "from training import train_model, train_model_CL\n",
    "from visualizations import plot_embeddings, plot_confusion_matrix\n",
    "from feature_attribution import Feature_Importance_Evaluations\n",
    "from pytorch_utils import get_features, get_labels\n",
    "from data_utils import initialize_data\n",
    "from embedding_measurements import measure_embedding_confusion_knn, measure_embedding_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = globals.SEED\n",
    "DEVICE = globals.DEVICE\n",
    "full_trainset = globals.full_trainset\n",
    "trainset = globals.trainset\n",
    "testset = globals.testset\n",
    "trainloaders = globals.trainloaders\n",
    "valloaders = globals.valloaders\n",
    "testloaders = globals.testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalModel(model, attr_device, i, only_pred = False):\n",
    "    accumPred = []\n",
    "    all_labels = []\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for j in range(i+1):\n",
    "            val_loader = globals.testloaders[j]\n",
    "            val_labels = get_labels(val_loader).to(attr_device)\n",
    "            model.eval()\n",
    "            pred, embeddings = model.get_pred_and_embeddings((get_features(val_loader).to(attr_device)))\n",
    "            model.train()\n",
    "            accumPred.append(pred)\n",
    "            if not only_pred:\n",
    "                all_embeddings.append(embeddings)\n",
    "                all_labels.append(val_labels)\n",
    "    accumPred = torch.cat(accumPred)\n",
    "    if not only_pred:\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_embeddings = torch.cat(all_embeddings)\n",
    "    if globals.OOD_CLASS == 1:\n",
    "        accumPred = accumPred[:,[i for i in range(accumPred.size(1)) if (i + 1) % (globals.CLASSES_PER_ITER+1) != 0]]\n",
    "    predicted = torch.argmax(accumPred, dim=1)\n",
    "    return predicted, all_labels, all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "        verbose = False,\n",
    "        full_CE = True,\n",
    "        with_OOD = False,\n",
    "        kd_loss = 0,\n",
    "        stopOnValAcc = None,\n",
    "        epochs = 1000000,\n",
    "        with_dropout = False,\n",
    "        optimiser_type = 'sgd',\n",
    "        dataset = 'mnist',\n",
    "        joint_training = False,\n",
    "        save_saliency=False,\n",
    "        plotting=False\n",
    "        ):\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    if dataset == 'tiny_imagenet':\n",
    "        ogd_basis_size=None\n",
    "        patience = 6\n",
    "        ood_method = 'fmix'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 200\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 40\n",
    "            globals.ITERATIONS = 5\n",
    "    elif dataset == 'mnist':\n",
    "        ogd_basis_size=200\n",
    "        patience = 2\n",
    "        ood_method = 'jigsaw'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 2\n",
    "            globals.ITERATIONS = 5\n",
    "    elif dataset == 'cifar10':\n",
    "        ogd_basis_size=50\n",
    "        patience = 4\n",
    "        ood_method = 'fmix'\n",
    "        if joint_training:\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "            globals.ITERATIONS = 1\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 2\n",
    "            globals.ITERATIONS = 5\n",
    "    if with_OOD:\n",
    "        globals.toggle_OOD(ood_method)\n",
    "    else:\n",
    "        globals.disable_OOD()\n",
    "    initialize_data(dataset)\n",
    "    prevModel = None\n",
    "    \n",
    "    globals.WITH_DROPOUT = with_dropout\n",
    "\n",
    "    #[Denis] added code:\n",
    "    if dataset == 'tiny_imagenet':\n",
    "        attr_device = 'cpu' # CPU has high memory in the cluster\n",
    "    else:\n",
    "        attr_device = globals.DEVICE\n",
    "    Feature_Importance_Eval=Feature_Importance_Evaluations(globals.testloaders, attr_device)\n",
    "\n",
    "    for i in tqdm(range(globals.ITERATIONS), desc=\"Experiment Progress\"):\n",
    "        if dataset == 'mnist':\n",
    "            model = MnistCNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        elif dataset == 'tiny_imagenet':\n",
    "            model = TinyImageNetCNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        elif dataset == 'cifar10':\n",
    "            model = Cifar10CNN((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        if prevModel is not None:\n",
    "            with torch.no_grad():\n",
    "                model.copyPrev(prevModel)\n",
    "        train_loader = globals.trainloaders[i]\n",
    "        val_loader = globals.valloaders[i]\n",
    "        if prevModel:\n",
    "            _print(\"CL TRAIN!!\")\n",
    "            model = train_model_CL(\n",
    "                model,\n",
    "                prevModel,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                i,\n",
    "                verbose,\n",
    "                epochs,\n",
    "                True,\n",
    "                kd_loss=kd_loss,\n",
    "                stopOnLoss=None,\n",
    "                stopOnValAcc = stopOnValAcc,\n",
    "                full_CE=full_CE,\n",
    "                optimiser_type=optimiser_type,\n",
    "                plotting=plotting,\n",
    "                patience=patience,\n",
    "                ogd_basis_size=ogd_basis_size\n",
    "                )\n",
    "        else:\n",
    "            _print(\"TRAINING!\")\n",
    "            model = train_model(\n",
    "                model, \n",
    "                train_loader,\n",
    "                val_loader, \n",
    "                verbose, \n",
    "                epochs=epochs, \n",
    "                stopOnLoss=None,\n",
    "                optimiser_type=optimiser_type,\n",
    "                plotting=plotting,\n",
    "                patience=patience,\n",
    "                ogd_basis_size=ogd_basis_size\n",
    "                )\n",
    "\n",
    "        #[Denis] added code:\n",
    "        Feature_Importance_Eval.Task_Feature_Attribution(model, i)\n",
    "        \n",
    "        if verbose or i == globals.ITERATIONS-1:\n",
    "            if dataset == 'tiny_imagenet':\n",
    "                model.to('cpu')\n",
    "            _print(\"Starting evaluation\")\n",
    "            _print(\"ITERATION\", i+1)\n",
    "            predicted, all_labels, all_embeddings = evalModel(model, attr_device, i)\n",
    "            if dataset == 'tiny_imagenet':\n",
    "                model.to(DEVICE)\n",
    "            predicted = predicted.to(attr_device)\n",
    "            correct = (predicted == all_labels).sum().item()  # Count how many were correct\n",
    "            accuracy = correct / all_labels.size(0)  # Accuracy as a percentage\n",
    "            _print(\"Accuracy on tasks so far:\", accuracy)\n",
    "            embedding_drift = measure_embedding_drift(all_embeddings, all_labels, model.prev_test_embedding_centers)\n",
    "            _print(\"Average embedding drift based on centroids:\", embedding_drift)\n",
    "            total_confusion, intra_phase_confusion, per_task_confusion = measure_embedding_confusion_knn(all_embeddings, all_labels, k = 300, task=i+1)\n",
    "            _print(\"Total confusion\", total_confusion)\n",
    "            _print(\"Intra-phase confusion\", intra_phase_confusion)\n",
    "            _print(\"Per task confusions\", per_task_confusion)\n",
    "            if verbose and dataset == 'mnist':\n",
    "                plot_confusion_matrix(predicted.cpu(), all_labels.cpu(), list(range(globals.CLASSES_PER_ITER*(i+1))))\n",
    "        prevModel = copy.deepcopy(model)\n",
    "        \n",
    "    #[Denis] added code:\n",
    "    [avg_att_diff,att_diffs,_,_,avg_att_spread,att_spreads]=Feature_Importance_Eval.Get_Feature_Change_Score(prevModel)\n",
    "    _print(\"Average SHAPC values (ordered as tasks):\", att_diffs)\n",
    "    _print(\"Averaged SHAPC value (the smaller the better):\", avg_att_diff)\n",
    "    _print(\"Average attention spread values (ordered as tasks):\", att_spreads)\n",
    "    _print(\"Averaged attention spread value (the bigger the better):\", avg_att_spread)\n",
    "    if save_saliency:\n",
    "        Feature_Importance_Eval.Save_Random_Picture_Salency() #prints the salcency maps for 1 example by class (first row: image, second row: salency map after training, third row: salency map after training task where class is included)\n",
    "    if not joint_training:\n",
    "        _print(\"Training output layer to check for bias...\")\n",
    "        model.output_layer.reset_parameters()\n",
    "        globals.ITERATIONS = 1\n",
    "        if dataset == 'mnist' or dataset == 'cifar10':\n",
    "            globals.CLASSES_PER_ITER = 10\n",
    "        else:\n",
    "            globals.CLASSES_PER_ITER = 200\n",
    "        model = train_model(\n",
    "                    model, \n",
    "                    DataLoader(globals.trainset, batch_size=globals.BATCH_SIZE, shuffle=True, pin_memory=True, num_workers = 0), \n",
    "                    DataLoader(globals.valset, batch_size=100, shuffle=False), \n",
    "                    verbose, \n",
    "                    epochs=epochs, \n",
    "                    stopOnLoss=None,\n",
    "                    optimiser_type='sgd',\n",
    "                    plotting=plotting,\n",
    "                    patience=patience,\n",
    "                    ogd_basis_size=ogd_basis_size,\n",
    "                    only_output_layer=True\n",
    "                    )\n",
    "        predicted, _, _ = evalModel(model, attr_device, i, True)\n",
    "        predicted = predicted.to(attr_device)\n",
    "        correct = (predicted == all_labels).sum().item()  # Count how many were correct\n",
    "        unbiased_output_accuracy = correct / all_labels.size(0)  # Accuracy as a percentage\n",
    "        output_bias = unbiased_output_accuracy-accuracy\n",
    "    else:\n",
    "        output_bias = 0\n",
    "    return accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread, output_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(n_runs=globals.EXPERIMENT_N_RUNS, *args, **kwargs):\n",
    "    verbose = kwargs.get('verbose', None)\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    def report_stats(data, name):\n",
    "        #print(name, data)\n",
    "        mean = statistics.mean(data)\n",
    "        std = statistics.stdev(data)\n",
    "        print(f\"Mean \" + name + f\" across {n_runs} runs: {mean}\")\n",
    "        print(f\"Standard deviation of \" + name + f\" across {n_runs} runs: {std}\\n\")\n",
    "    accuracies = []\n",
    "    total_confusions = []\n",
    "    intra_phase_confusions = []\n",
    "    per_task_confusions = []\n",
    "    att_diffs = []\n",
    "    embedding_drifts = []\n",
    "    att_spreads = []\n",
    "    output_biases = []\n",
    "    for r in range(n_runs):\n",
    "        print(f\"Starting run {r+1}.\")\n",
    "        accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread, output_bias = run_experiment(*args, **kwargs)\n",
    "        accuracies.append(accuracy)\n",
    "        total_confusions.append(total_confusion)\n",
    "        intra_phase_confusions.append(intra_phase_confusion)\n",
    "        per_task_confusions.append(per_task_confusion)\n",
    "        att_diffs.append(avg_att_diff)\n",
    "        embedding_drifts.append(embedding_drift)\n",
    "        att_spreads.append(avg_att_spread)\n",
    "        output_biases.append(output_bias)\n",
    "        print(f\"Run {r} finished with accuracy {accuracy}\")\n",
    "\n",
    "    report_stats(accuracies, \"accuracy\")\n",
    "    report_stats(total_confusions, \"total confusion\")\n",
    "    report_stats(intra_phase_confusions, \"intra-phase confusion\")\n",
    "    report_stats(per_task_confusions, \"per-task confusion\")\n",
    "    report_stats(output_biases, \"output bias\")\n",
    "    report_stats(embedding_drifts, \"embedding drift\")\n",
    "    report_stats(att_diffs, \"attention drift\")\n",
    "    report_stats(att_spreads, \"attention spread\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5) # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, full_CE=False) # baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, optimiser_type='ogd') # baseline with OGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, optimiser_type='adam') # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True, optimiser_type='ogd') # everything without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False, optimiser_type='ogd') # everything without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # everything with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam') # everything with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='mnist', n_runs=5, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for CIFAR10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3) # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, full_CE=False) # baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, optimiser_type='ogd') # baseline with OGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, optimiser_type='adam') # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True, optimiser_type='ogd') # everything without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', verbose=True, n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False, optimiser_type='ogd') # everything without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True, optimiser_type='ogd') # everything without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', verbose=True, n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # everything with sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam') # everything with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='cifar10', n_runs=3, joint_training=True) # joint training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments for tiny imagenet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3) # baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, full_CE=False) # baseline with special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_OOD=True) # baseline with OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True) # baseline with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, kd_loss=1) # baseline with KD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, optimiser_type='ogd') # baseline with OGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, optimiser_type='adam') # baseline with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', verbose=True, n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # everything (no ogd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', verbose=True, n_runs=3, with_dropout=True, kd_loss=1, full_CE=True, with_OOD=True, optimiser_type='sgd') # everything (no ogd) without special CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False, optimiser_type='sgd') # everything (no ogd) without OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='sgd') # everything (no ogd) without dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=0, full_CE=False, with_OOD=True, optimiser_type='sgd') # everything (no ogd) without kd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, optimiser_type='adam') # everything with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiments(dataset='tiny_imagenet', n_runs=3, joint_training=True) # joint training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
