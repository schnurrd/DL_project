{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import copy\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./../src')\n",
    "import globals\n",
    "from model import Net\n",
    "from training import train_model, train_model_CL\n",
    "from visualizations import plot_embeddings, plot_confusion_matrix\n",
    "from feature_attribution import Feature_Importance_Evaluations\n",
    "from pytorch_utils import get_features, get_labels\n",
    "from embedding_measurements import measure_embedding_confusion_knn, measure_embedding_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submitit\n",
    "import os\n",
    "partition_nr = 1\n",
    "partition = 'mlhiwidlc_gpu-rtx2080' if partition_nr == 0 else \"mlhiwidlc_gpu-rtx2080-advanced\" if partition_nr == 1 else \"testdlc_gpu-rtx2080\"\n",
    "\n",
    "timelimit_hours = 2\n",
    "num_gpus_per_node = 1\n",
    "num_jobs = 1\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "log_path = os.path.join(parent_dir, 'submitit_logs')\n",
    "run_path = os.path.join(parent_dir, 'src')\n",
    "\n",
    "\n",
    "ex_parallel = submitit.AutoExecutor(folder=log_path)\n",
    "ex_parallel.update_parameters(\n",
    "        slurm_signal_delay_s=180,           # time to pass the USR2 signal to slurm before the job times out so that it can finish the run\n",
    "        tasks_per_node=num_gpus_per_node,\n",
    "        nodes=1,\n",
    "        slurm_partition=partition,\n",
    "        timeout_min=int(timelimit_hours*60),\n",
    "        cpus_per_task=8,\n",
    "        slurm_gres=f'gpu:{num_gpus_per_node}',\n",
    "        slurm_setup = [f'export PYTHONPATH=\"${{PYTHONPATH}}:{run_path}\"'],\n",
    "    )\n",
    "\n",
    "SEED = globals.SEED\n",
    "DEVICE = globals.DEVICE  # torch.device(\"cuda:0\")\n",
    "full_trainset = globals.full_trainset\n",
    "trainset = globals.trainset\n",
    "testset = globals.testset\n",
    "trainloaders = globals.trainloaders\n",
    "valloaders = globals.valloaders\n",
    "testloaders = globals.testloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the two-step process used to prepare the\n",
    "# data for use with the convolutional neural network.\n",
    "\n",
    "# First step is to convert Python Image Library (PIL) format\n",
    "# to PyTorch tensors.\n",
    "\n",
    "# Second step is used to normalize the data by specifying a \n",
    "# mean and standard deviation for each of the three channels.\n",
    "# This will convert the data from [0,1] to [-1,1]\n",
    "\n",
    "# Normalization of data should help speed up conversion and\n",
    "# reduce the chance of vanishing gradients with certain \n",
    "# activation functions.\n",
    "def initialize_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        #transforms.Normalize((0.5,), (0.5,))  # Normalizes to mean 0.5 and std 0.5 for the single channel\n",
    "    ])\n",
    "\n",
    "    globals.full_trainset = torchvision.datasets.MNIST('./../data/', train=True, download=True,\n",
    "                                transform=transform)\n",
    "    targets = np.array(globals.full_trainset.targets)\n",
    "\n",
    "    if globals.val_set_size != 0:\n",
    "        # Perform stratified split\n",
    "        train_indices, val_indices = train_test_split(\n",
    "            np.arange(len(targets)),\n",
    "            test_size=0.01,\n",
    "            stratify=targets\n",
    "        )\n",
    "    else:\n",
    "        train_indices = np.arange(len(targets))\n",
    "        val_indices = []\n",
    "\n",
    "    # Create subsets\n",
    "    valset = Subset(globals.full_trainset, val_indices)\n",
    "    globals.trainset = Subset(globals.full_trainset, train_indices)\n",
    "\n",
    "    globals.testset = torchvision.datasets.MNIST('./../data/', train=False, download=True,\n",
    "                                transform=transform)\n",
    "\n",
    "    # Define class pairs for each subset\n",
    "    class_pairs = [tuple(range(i*globals.CLASSES_PER_ITER,(i+1)*globals.CLASSES_PER_ITER)) for i in range(globals.ITERATIONS)]\n",
    "    #print(class_pairs)\n",
    "\n",
    "    # Dictionary to hold data loaders for each subset\n",
    "    globals.trainloaders = []\n",
    "    globals.testloaders = []\n",
    "    globals.valloaders = []\n",
    "    subset_indices = []\n",
    "    # Loop over each class pair\n",
    "    for i, t in enumerate(class_pairs):\n",
    "        # Get indices of images belonging to the specified class pair\n",
    "        subs_ind = [idx for idx, (_, label) in enumerate(globals.trainset) if label in list(t)]\n",
    "        val_subset_indices = [idx for idx, (_, label) in enumerate(valset) if label in list(t)]\n",
    "        test_subset_indices = [idx for idx, (_, label) in enumerate(globals.testset) if label in list(t)]\n",
    "        # Create a subset for the current class pair\n",
    "        train_subset = Subset(globals.trainset, subs_ind)\n",
    "        globals.trainloaders.append(DataLoader(train_subset, batch_size=globals.BATCH_SIZE, shuffle=True, pin_memory=True, num_workers = 0))\n",
    "\n",
    "        subset_indices.append(subs_ind)\n",
    "        \n",
    "        val_subset = Subset(valset, val_subset_indices)\n",
    "        globals.valloaders.append(DataLoader(val_subset, batch_size=500, shuffle=False))\n",
    "\n",
    "        test_subset = Subset(globals.testset, test_subset_indices)\n",
    "        globals.testloaders.append(DataLoader(test_subset, batch_size=500, shuffle=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "        verbose = False,\n",
    "        stopOnLoss = 0.02,\n",
    "        full_CE = True,\n",
    "        with_OOD = False,\n",
    "        ood_method = 'jigsaw',\n",
    "        kd_loss = 0,\n",
    "        stopOnValAcc = None,\n",
    "        epochs = 1000000,\n",
    "        with_dropout = False,\n",
    "        ogd = False\n",
    "        ):\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    if with_OOD:\n",
    "        globals.toggle_OOD(ood_method)\n",
    "    else:\n",
    "        globals.disable_OOD()\n",
    "    initialize_data()\n",
    "    prevModel = None\n",
    "    globals.BATCH_SIZE=4\n",
    "    \n",
    "    globals.WITH_DROPOUT = with_dropout\n",
    "\n",
    "    #[Denis] added code:\n",
    "    Feature_Importance_Eval=Feature_Importance_Evaluations(globals.testloaders, DEVICE)\n",
    "\n",
    "    for i in tqdm(range(globals.ITERATIONS), desc=\"Experiment Progress\"):\n",
    "        model = Net((i+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS))\n",
    "        if prevModel is not None:\n",
    "            with torch.no_grad():\n",
    "                model.copyPrev(prevModel)\n",
    "        train_loader = globals.trainloaders[i]\n",
    "        val_loader = globals.valloaders[i]\n",
    "        if prevModel:\n",
    "            _print(\"CL TRAIN!!\")\n",
    "            train_model_CL(\n",
    "                model,\n",
    "                prevModel,\n",
    "                train_loader,\n",
    "                val_loader,\n",
    "                i,\n",
    "                verbose,\n",
    "                epochs,\n",
    "                True,\n",
    "                freeze_nonzero_params=False,\n",
    "                l1_loss=0,\n",
    "                ewc_loss=0,\n",
    "                kd_loss=kd_loss,\n",
    "                distance_loss=0,\n",
    "                center_loss=0,\n",
    "                param_reuse_loss=0,\n",
    "                stopOnLoss=stopOnLoss,\n",
    "                stopOnValAcc = stopOnValAcc,\n",
    "                full_CE=full_CE,\n",
    "                ogd=ogd,\n",
    "                )\n",
    "        else:\n",
    "            train_model(\n",
    "                model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                verbose, \n",
    "                epochs=epochs, \n",
    "                l1_loss=0,\n",
    "                stopOnLoss=stopOnLoss,\n",
    "                center_loss =0,\n",
    "                ogd=ogd\n",
    "                )\n",
    "\n",
    "        #[Denis] added code:\n",
    "        Feature_Importance_Eval.Task_Feature_Attribution(model, i)\n",
    "        \n",
    "        if verbose or i == globals.ITERATIONS-1:\n",
    "            _print(\"Starting evaluation\")\n",
    "            _print(\"ITERATION\", i+1)\n",
    "            _print(\"ACCURACIES PER TASK:\")\n",
    "            accumPred = []\n",
    "            all_labels = []\n",
    "            all_embeddings = []\n",
    "            with torch.no_grad():\n",
    "                for j in range(i+1):\n",
    "                    val_loader = globals.testloaders[j]\n",
    "                    val_labels = get_labels(val_loader).to(DEVICE)\n",
    "                    all_labels.append(val_labels)\n",
    "                    model.eval()\n",
    "                    pred, embeddings = model.get_pred_and_embeddings((get_features(val_loader).to(DEVICE)))\n",
    "                    model.train()\n",
    "                    accumPred.append(pred)\n",
    "                    all_embeddings.append(embeddings)\n",
    "                    sliced_pred = pred[:, j*(globals.CLASSES_PER_ITER+globals.OOD_CLASS):(j+1)*(globals.CLASSES_PER_ITER+globals.OOD_CLASS)]\n",
    "                    _, predicted = torch.max(sliced_pred, 1)  # Get the class predictions\n",
    "                    predicted += j*globals.CLASSES_PER_ITER\n",
    "                    correct = (predicted == val_labels).sum().item()  # Count how many were correct\n",
    "                    accuracy = correct / val_labels.size(0)  # Accuracy as a percentage\n",
    "                    _print(str(accuracy), end=' ')\n",
    "            accumPred = torch.cat(accumPred)\n",
    "            all_labels = torch.cat(all_labels)\n",
    "            all_embeddings = torch.cat(all_embeddings)\n",
    "            predicted = []\n",
    "            for x in accumPred:\n",
    "                if globals.OOD_CLASS == 1:\n",
    "                    x_pred = x[[i for i in range(x.size(0)) if (i + 1) % (globals.CLASSES_PER_ITER+1) != 0]]\n",
    "                else:\n",
    "                    x_pred = x\n",
    "                x_pred = torch.softmax(x_pred, dim=-1)\n",
    "                max = 0\n",
    "                for (k, v) in enumerate(x_pred):\n",
    "                    if v > max:\n",
    "                        max = v\n",
    "                        p = k\n",
    "                predicted.append(p)\n",
    "            predicted = torch.tensor(predicted).to(DEVICE)\n",
    "            correct = (predicted == all_labels).sum().item()  # Count how many were correct\n",
    "            accuracy = correct / all_labels.size(0)  # Accuracy as a percentage\n",
    "            _print(\"Accuracy on tasks so far:\", accuracy)\n",
    "\n",
    "            embedding_drift = measure_embedding_drift(all_embeddings, all_labels, model.prev_test_embedding_centers)\n",
    "            _print(\"Average embedding drift based on centroids:\", embedding_drift)\n",
    "            total_confusion, intra_phase_confusion, per_task_confusion = measure_embedding_confusion_knn(all_embeddings, all_labels, k = 1000, task=i+1)\n",
    "            _print(\"Total confusion\", total_confusion)\n",
    "            _print(\"Intra-phase confusion\", intra_phase_confusion)\n",
    "            _print(\"Per task confusions\", per_task_confusion)\n",
    "            if verbose:\n",
    "                plot_confusion_matrix(predicted.cpu(), all_labels.cpu(), list(range(globals.CLASSES_PER_ITER*(i+1))))\n",
    "        prevModel = copy.deepcopy(model)\n",
    "        \n",
    "    #[Denis] added code:\n",
    "    [avg_att_diff,att_diffs,_,_,avg_att_spread,att_spreads]=Feature_Importance_Eval.Get_Feature_Change_Score(prevModel)\n",
    "    _print(\"Average SHAPC values (ordered as tasks):\", att_diffs)\n",
    "    _print(\"Averaged SHAPC value (the smaller the better):\", avg_att_diff)\n",
    "    _print(\"Average attention spread values (ordered as tasks):\", att_spreads)\n",
    "    _print(\"Averaged attention spread value (the bigger the better):\", avg_att_spread)\n",
    "    Feature_Importance_Eval.Save_Random_Picture_Salency() #prints the salcency maps for 1 example by class (first row: image, second row: salency map after training, third row: salency map after training task where class is included)\n",
    "    \n",
    "    return accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(n_runs=globals.EXPERIMENT_N_RUNS, *args, **kwargs):\n",
    "    verbose = kwargs.get('verbose', None)\n",
    "    def _print(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    def report_stats(data, name):\n",
    "        #print(name, data)\n",
    "        mean = statistics.mean(data)\n",
    "        std = statistics.stdev(data)\n",
    "        print(f\"Mean \" + name + f\" across {n_runs} runs: {mean}\")\n",
    "        print(f\"Standard deviation of \" + name + f\" across {n_runs} runs: {std}\\n\")\n",
    "    accuracies = []\n",
    "    total_confusions = []\n",
    "    intra_phase_confusions = []\n",
    "    per_task_confusions = []\n",
    "    att_diffs = []\n",
    "    embedding_drifts = []\n",
    "    att_spreads = []\n",
    "\n",
    "    jobs = []\n",
    "    for r in range(n_runs):\n",
    "        print(f\"Starting run {r+1}.\")\n",
    "        # jobs.append(ex_parallel.submit(run_experiment,*args, **kwargs))\n",
    "        jobs.append(run_experiment(*args, **kwargs))\n",
    "    for i, job in enumerate(jobs):\n",
    "        accuracy, total_confusion, intra_phase_confusion, per_task_confusion, embedding_drift, avg_att_diff, avg_att_spread = job.result()\n",
    "        accuracies.append(accuracy)\n",
    "        total_confusions.append(total_confusion)\n",
    "        intra_phase_confusions.append(intra_phase_confusion)\n",
    "        per_task_confusions.append(per_task_confusion)\n",
    "        att_diffs.append(avg_att_diff)\n",
    "        embedding_drifts.append(embedding_drift)\n",
    "        att_spreads.append(avg_att_spread)\n",
    "        print(f\"Run {i} finished with accuracy {accuracy}\")\n",
    "\n",
    "    report_stats(accuracies, \"accuracy\")\n",
    "    report_stats(total_confusions, \"total confusion\")\n",
    "    report_stats(intra_phase_confusions, \"intra-phase confusion\")\n",
    "    report_stats(per_task_confusions, \"per-task confusion\")\n",
    "    report_stats(embedding_drifts, \"embedding drift\")\n",
    "    report_stats(att_diffs, \"attention drift\")\n",
    "    report_stats(att_spreads, \"attention spread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.19729\n",
      "Standard deviation of accuracy across 20 runs: 0.0003093286448525514\n",
      "\n",
      "Mean total confusion across 20 runs: 0.414515965\n",
      "Standard deviation of total confusion across 20 runs: 0.01604952756728125\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.407553005\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.015778470434289985\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.08277860201892084\n",
      "Standard deviation of per-task confusion across 20 runs: 0.007983167678031429\n",
      "\n",
      "Mean embedding drift across 20 runs: 9.900845670700074\n",
      "Standard deviation of embedding drift across 20 runs: 0.4113766512724969\n",
      "\n",
      "Mean attention drift across 20 runs: 7.325360312353875e-06\n",
      "Standard deviation of attention drift across 20 runs: 9.228132386212315e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 56.67999437612826\n",
      "Standard deviation of attention spread across 20 runs: 3.1532041104133484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.19776\n",
      "Standard deviation of accuracy across 20 runs: 0.00012732056517228836\n",
      "\n",
      "Mean total confusion across 20 runs: 0.447576495\n",
      "Standard deviation of total confusion across 20 runs: 0.02142939851019906\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.43697244\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.020965855806761014\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.11613773286171956\n",
      "Standard deviation of per-task confusion across 20 runs: 0.011780864824994837\n",
      "\n",
      "Mean embedding drift across 20 runs: 8.883338165283202\n",
      "Standard deviation of embedding drift across 20 runs: 0.3353551149334345\n",
      "\n",
      "Mean attention drift across 20 runs: 9.46104026046783e-06\n",
      "Standard deviation of attention drift across 20 runs: 7.924499763520329e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 56.79674318965892\n",
      "Standard deviation of attention spread across 20 runs: 2.28769802686983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.20146\n",
      "Standard deviation of accuracy across 20 runs: 0.006270180052816414\n",
      "\n",
      "Mean total confusion across 20 runs: 0.378874945\n",
      "Standard deviation of total confusion across 20 runs: 0.010659788842308506\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.37555696\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.010214348913964638\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.06480042035742914\n",
      "Standard deviation of per-task confusion across 20 runs: 0.0066560068670996385\n",
      "\n",
      "Mean embedding drift across 20 runs: 10.568913745880128\n",
      "Standard deviation of embedding drift across 20 runs: 0.4949920468295522\n",
      "\n",
      "Mean attention drift across 20 runs: 6.87858509841904e-06\n",
      "Standard deviation of attention drift across 20 runs: 9.906909991621907e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 54.6448284471033\n",
      "Standard deviation of attention spread across 20 runs: 2.441945264996964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(kd_loss=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.623225\n",
      "Standard deviation of accuracy across 20 runs: 0.0612067580977959\n",
      "\n",
      "Mean total confusion across 20 runs: 0.42478873500000003\n",
      "Standard deviation of total confusion across 20 runs: 0.015463924293633774\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.4224134\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.01526683802622361\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.06788457927885161\n",
      "Standard deviation of per-task confusion across 20 runs: 0.005847927349584258\n",
      "\n",
      "Mean embedding drift across 20 runs: 5.491150999069214\n",
      "Standard deviation of embedding drift across 20 runs: 0.29895133171735105\n",
      "\n",
      "Mean attention drift across 20 runs: 2.576269053044406e-06\n",
      "Standard deviation of attention drift across 20 runs: 2.5080119028186776e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 48.19473430599393\n",
      "Standard deviation of attention spread across 20 runs: 1.4846543950919158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(full_CE=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.19753\n",
      "Standard deviation of accuracy across 20 runs: 0.001541393764371096\n",
      "\n",
      "Mean total confusion across 20 runs: 0.348665625\n",
      "Standard deviation of total confusion across 20 runs: 0.0200980931129214\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.341661555\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.017989925005591774\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.07377787103441767\n",
      "Standard deviation of per-task confusion across 20 runs: 0.012119888500722348\n",
      "\n",
      "Mean embedding drift across 20 runs: 11.41977047920227\n",
      "Standard deviation of embedding drift across 20 runs: 0.6377873246918927\n",
      "\n",
      "Mean attention drift across 20 runs: 3.382936368916668e-06\n",
      "Standard deviation of attention drift across 20 runs: 3.4614475748721674e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 70.60566178216719\n",
      "Standard deviation of attention spread across 20 runs: 5.491672770992813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_OOD=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.198135\n",
      "Standard deviation of accuracy across 20 runs: 0.003945853919989274\n",
      "\n",
      "Mean total confusion across 20 runs: 0.40074635000000003\n",
      "Standard deviation of total confusion across 20 runs: 0.014681977910546968\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.39745372\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.014508483057620572\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.07140316540583184\n",
      "Standard deviation of per-task confusion across 20 runs: 0.005296685010696834\n",
      "\n",
      "Mean embedding drift across 20 runs: 10.762645626068116\n",
      "Standard deviation of embedding drift across 20 runs: 0.8291818018837278\n",
      "\n",
      "Mean attention drift across 20 runs: 1.9699910445314466e-06\n",
      "Standard deviation of attention drift across 20 runs: 2.690139868216657e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 51.63454439896025\n",
      "Standard deviation of attention spread across 20 runs: 2.0069901827297705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(ogd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Mean accuracy across 20 runs: 0.86777\n",
      "Standard deviation of accuracy across 20 runs: 0.013602867344791695\n",
      "\n",
      "Mean total confusion across 20 runs: 0.310928865\n",
      "Standard deviation of total confusion across 20 runs: 0.0067708420616232985\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.30854194\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.0066880282271974305\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.050800132754598215\n",
      "Standard deviation of per-task confusion across 20 runs: 0.0018811041010954434\n",
      "\n",
      "Mean embedding drift across 20 runs: 4.782956767082214\n",
      "Standard deviation of embedding drift across 20 runs: 0.2704109716467063\n",
      "\n",
      "Mean attention drift across 20 runs: 1.2213010708519556e-06\n",
      "Standard deviation of attention drift across 20 runs: 7.634997504885134e-08\n",
      "\n",
      "Mean attention spread across 20 runs: 62.2649797035649\n",
      "Standard deviation of attention spread across 20 runs: 3.264222089533471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, ogd=True) # best version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Run 0 finished with accuracy 0.8527\n",
      "Run 1 finished with accuracy 0.8573\n",
      "Run 2 finished with accuracy 0.8746\n",
      "Run 3 finished with accuracy 0.8791\n",
      "Run 4 finished with accuracy 0.8469\n",
      "Run 5 finished with accuracy 0.8244\n",
      "Run 6 finished with accuracy 0.8274\n",
      "Run 7 finished with accuracy 0.8593\n",
      "Run 8 finished with accuracy 0.8573\n",
      "Run 9 finished with accuracy 0.8778\n",
      "Run 10 finished with accuracy 0.8343\n",
      "Run 11 finished with accuracy 0.8767\n",
      "Run 12 finished with accuracy 0.8693\n",
      "Run 13 finished with accuracy 0.8545\n",
      "Run 14 finished with accuracy 0.8693\n",
      "Run 15 finished with accuracy 0.859\n",
      "Run 16 finished with accuracy 0.851\n",
      "Run 17 finished with accuracy 0.8699\n",
      "Run 18 finished with accuracy 0.8523\n",
      "Run 19 finished with accuracy 0.8319\n",
      "Mean accuracy across 20 runs: 0.85625\n",
      "Standard deviation of accuracy across 20 runs: 0.01678842019463353\n",
      "\n",
      "Mean total confusion across 20 runs: 0.313218785\n",
      "Standard deviation of total confusion across 20 runs: 0.009351078569385244\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.31095848\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.009343033399479495\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.0506131863200927\n",
      "Standard deviation of per-task confusion across 20 runs: 0.0020453258701410245\n",
      "\n",
      "Mean embedding drift across 20 runs: 5.087467122077942\n",
      "Standard deviation of embedding drift across 20 runs: 0.2106567900527496\n",
      "\n",
      "Mean attention drift across 20 runs: 1.5258862093204534e-06\n",
      "Standard deviation of attention drift across 20 runs: 1.0618570081924518e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 58.35392073942707\n",
      "Standard deviation of attention spread across 20 runs: 2.0642299576250163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_dropout=True, kd_loss=1, full_CE=False, with_OOD=True, ogd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Run 0 finished with accuracy 0.8399\n",
      "Run 1 finished with accuracy 0.8056\n",
      "Run 2 finished with accuracy 0.7323\n",
      "Run 3 finished with accuracy 0.8221\n",
      "Run 4 finished with accuracy 0.7856\n",
      "Run 5 finished with accuracy 0.8099\n",
      "Run 6 finished with accuracy 0.7452\n",
      "Run 7 finished with accuracy 0.7821\n",
      "Run 8 finished with accuracy 0.7926\n",
      "Run 9 finished with accuracy 0.7991\n",
      "Run 10 finished with accuracy 0.8117\n",
      "Run 11 finished with accuracy 0.7414\n",
      "Run 12 finished with accuracy 0.8436\n",
      "Run 13 finished with accuracy 0.8162\n",
      "Run 14 finished with accuracy 0.8319\n",
      "Run 15 finished with accuracy 0.7562\n",
      "Run 16 finished with accuracy 0.7717\n",
      "Run 17 finished with accuracy 0.8371\n",
      "Run 18 finished with accuracy 0.8049\n",
      "Run 19 finished with accuracy 0.8079\n",
      "Mean accuracy across 20 runs: 0.79685\n",
      "Standard deviation of accuracy across 20 runs: 0.03333642704941628\n",
      "\n",
      "Mean total confusion across 20 runs: 0.3613555\n",
      "Standard deviation of total confusion across 20 runs: 0.009606716636976324\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.35659022\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.00948110171938173\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.0749763665572216\n",
      "Standard deviation of per-task confusion across 20 runs: 0.003964972114386648\n",
      "\n",
      "Mean embedding drift across 20 runs: 4.784511709213257\n",
      "Standard deviation of embedding drift across 20 runs: 0.1661071945358487\n",
      "\n",
      "Mean attention drift across 20 runs: 5.697647139896333e-07\n",
      "Standard deviation of attention drift across 20 runs: 4.549564399890445e-08\n",
      "\n",
      "Mean attention spread across 20 runs: 78.04319710329132\n",
      "Standard deviation of attention spread across 20 runs: 2.7930613104865722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_dropout=False, kd_loss=1, full_CE=False, with_OOD=True, ogd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Run 0 finished with accuracy 0.8119\n",
      "Run 1 finished with accuracy 0.7824\n",
      "Run 2 finished with accuracy 0.7514\n",
      "Run 3 finished with accuracy 0.7462\n",
      "Run 4 finished with accuracy 0.7386\n",
      "Run 5 finished with accuracy 0.7901\n",
      "Run 6 finished with accuracy 0.76\n",
      "Run 7 finished with accuracy 0.7492\n",
      "Run 8 finished with accuracy 0.8001\n",
      "Run 9 finished with accuracy 0.7887\n",
      "Run 10 finished with accuracy 0.696\n",
      "Run 11 finished with accuracy 0.7436\n",
      "Run 12 finished with accuracy 0.7926\n",
      "Run 13 finished with accuracy 0.7333\n",
      "Run 14 finished with accuracy 0.7811\n",
      "Run 15 finished with accuracy 0.7462\n",
      "Run 16 finished with accuracy 0.7443\n",
      "Run 17 finished with accuracy 0.7516\n",
      "Run 18 finished with accuracy 0.7981\n",
      "Run 19 finished with accuracy 0.7456\n",
      "Mean accuracy across 20 runs: 0.76255\n",
      "Standard deviation of accuracy across 20 runs: 0.029013889595738186\n",
      "\n",
      "Mean total confusion across 20 runs: 0.38249867\n",
      "Standard deviation of total confusion across 20 runs: 0.008206072496447203\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.380793265\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.008190212029533222\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.056004723636445757\n",
      "Standard deviation of per-task confusion across 20 runs: 0.0024343495873523\n",
      "\n",
      "Mean embedding drift across 20 runs: 4.268457651138306\n",
      "Standard deviation of embedding drift across 20 runs: 0.20534457404186274\n",
      "\n",
      "Mean attention drift across 20 runs: 1.1627860903915834e-06\n",
      "Standard deviation of attention drift across 20 runs: 6.070007306550722e-08\n",
      "\n",
      "Mean attention spread across 20 runs: 50.75548357324772\n",
      "Standard deviation of attention spread across 20 runs: 1.7182102549471816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiments(with_dropout=True, kd_loss=1, full_CE=False, with_OOD=False, ogd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1.\n",
      "Starting run 2.\n",
      "Starting run 3.\n",
      "Starting run 4.\n",
      "Starting run 5.\n",
      "Starting run 6.\n",
      "Starting run 7.\n",
      "Starting run 8.\n",
      "Starting run 9.\n",
      "Starting run 10.\n",
      "Starting run 11.\n",
      "Starting run 12.\n",
      "Starting run 13.\n",
      "Starting run 14.\n",
      "Starting run 15.\n",
      "Starting run 16.\n",
      "Starting run 17.\n",
      "Starting run 18.\n",
      "Starting run 19.\n",
      "Starting run 20.\n",
      "Run 0 finished with accuracy 0.1967\n",
      "Run 1 finished with accuracy 0.197\n",
      "Run 2 finished with accuracy 0.1976\n",
      "Run 3 finished with accuracy 0.1957\n",
      "Run 4 finished with accuracy 0.1968\n",
      "Run 5 finished with accuracy 0.1975\n",
      "Run 6 finished with accuracy 0.1977\n",
      "Run 7 finished with accuracy 0.1939\n",
      "Run 8 finished with accuracy 0.1976\n",
      "Run 9 finished with accuracy 0.1974\n",
      "Run 10 finished with accuracy 0.1965\n",
      "Run 11 finished with accuracy 0.1976\n",
      "Run 12 finished with accuracy 0.1974\n",
      "Run 13 finished with accuracy 0.1974\n",
      "Run 14 finished with accuracy 0.1975\n",
      "Run 15 finished with accuracy 0.1973\n",
      "Run 16 finished with accuracy 0.1969\n",
      "Run 17 finished with accuracy 0.1976\n",
      "Run 18 finished with accuracy 0.1977\n",
      "Run 19 finished with accuracy 0.1973\n",
      "Mean accuracy across 20 runs: 0.197055\n",
      "Standard deviation of accuracy across 20 runs: 0.0008947066558375425\n",
      "\n",
      "Mean total confusion across 20 runs: 0.407966305\n",
      "Standard deviation of total confusion across 20 runs: 0.016540122758994427\n",
      "\n",
      "Mean intra-phase confusion across 20 runs: 0.401076215\n",
      "Standard deviation of intra-phase confusion across 20 runs: 0.015769586089661225\n",
      "\n",
      "Mean per-task confusion across 20 runs: 0.08277211409923732\n",
      "Standard deviation of per-task confusion across 20 runs: 0.00757838820029887\n",
      "\n",
      "Mean embedding drift across 20 runs: 9.779425477981567\n",
      "Standard deviation of embedding drift across 20 runs: 0.4738672231773042\n",
      "\n",
      "Mean attention drift across 20 runs: 7.1896323526120425e-06\n",
      "Standard deviation of attention drift across 20 runs: 9.870221064884275e-07\n",
      "\n",
      "Mean attention spread across 20 runs: 56.59669137918274\n",
      "Standard deviation of attention spread across 20 runs: 1.6400096725950695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training on entire dataset\n",
    "globals.ITERATIONS = 1\n",
    "globals.CLASSES_PER_ITER = 10\n",
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
